{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnshulH/NLP-DL-Group2/blob/lstm/NLP_Project_1_Bi-LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7U7h5_g6HQj",
        "outputId": "e9a0a256-efd4-49ac-d88a-ea37cf1460ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/NLP-DL-Group2/': No such file or directory\n",
            "Cloning into 'NLP-DL-Group2'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 105 (delta 26), reused 18 (delta 5), pack-reused 46\u001b[K\n",
            "Receiving objects: 100% (105/105), 30.84 MiB | 15.62 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "Updating files: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r /content/NLP-DL-Group2/\n",
        "!cd /content && git clone https://github.com/AnshulH/NLP-DL-Group2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words # added for detecting English words\n",
        "import string\n",
        "import nltk\n",
        "import calendar\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3BjxK9QyXLA",
        "outputId": "4fdc729e-186a-4dae-9765-679b58474c62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(vocab,corpus):\n",
        "    \n",
        "    text = ''\n",
        "    for i in range(len(corpus)):\n",
        "        wID = corpus[i]\n",
        "        text = text + vocab[wID] + ' '\n",
        "    return(text)\n",
        "\n",
        "def encode(words,text):\n",
        "    corpus = []\n",
        "    tokens = text.split(' ')\n",
        "    for t in tokens:\n",
        "        try:\n",
        "            wID = words[t][0]\n",
        "        except:\n",
        "            wID = words['<unk>'][0]\n",
        "        corpus.append(wID)\n",
        "    return(corpus)\n",
        "\n",
        "def read_encode(file_name,vocab,words,corpus,threshold):\n",
        "    \n",
        "    wID = len(vocab)\n",
        "    \n",
        "    if threshold > -1:\n",
        "        with open(file_name,'rt') as f:\n",
        "            for line in f:\n",
        "                line = line.replace('\\n','')\n",
        "                tokens = line.split(' ')\n",
        "                for t in tokens:\n",
        "                    try:\n",
        "                        elem = words[t]\n",
        "                    except:\n",
        "                        elem = [wID,0]\n",
        "                        vocab.append(t)\n",
        "                        wID = wID + 1\n",
        "                    elem[1] = elem[1] + 1\n",
        "                    words[t] = elem\n",
        "\n",
        "        temp = words\n",
        "        words = {}\n",
        "        vocab = []\n",
        "        wID = 0\n",
        "        words['<unk>'] = [wID,100]\n",
        "        wID = 1\n",
        "        words['<pad>'] = [wID,100]\n",
        "        wID = 2\n",
        "        words['<num>'] = [wID,100]\n",
        "        wID = 3\n",
        "        words['< end_bio >'] = [wID,100]\n",
        "        vocab.append('<unk>')\n",
        "        vocab.append('<pad>')\n",
        "        vocab.append('<num>')\n",
        "        vocab.append('< end_bio >')\n",
        "        for t in temp:\n",
        "            if temp[t][1] >= threshold:\n",
        "                vocab.append(t)\n",
        "                wID = wID + 1\n",
        "                words[t] = [wID,temp[t][1]]\n",
        "            \n",
        "                    \n",
        "    with open(file_name,'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.replace('\\n','')\n",
        "            tokens = line.split(' ')\n",
        "            for t in tokens:\n",
        "                try:\n",
        "                    wID = words[t][0]\n",
        "                except:\n",
        "                    wID = words['<unk>'][0]\n",
        "                corpus.append(wID)\n",
        "                \n",
        "    return [vocab,words,corpus]\n",
        "\n",
        "def read_alltext(file_name,batch_size):\n",
        "  '''\n",
        "  tokenizes data, removes digits, converts to wIDs, and provides a tensor of batched inputs\n",
        "\n",
        "  inputs: \n",
        "    file_name = a complete file path to a mixed dataset containing text and labels\n",
        "    sequence_length = the length of the desired input array\n",
        "  outputs:\n",
        "    x = a tensor containing wIDs of the input\n",
        "  '''\n",
        "  encodings = read_encode(file_name,[],{},[],3)\n",
        "  word_dict = encodings[1]\n",
        "  wid = []\n",
        "\n",
        "  with open(file_name) as input:\n",
        "    all_text = input.readlines()\n",
        "\n",
        "  for line in all_text[:2000]:\n",
        "    line = line.strip()\n",
        "    line = re.sub(\"[\\d-]\", \"\",line)\n",
        "    line = [token for token in word_tokenize(line.lower())]\n",
        "    for token in line:\n",
        "      word_info = word_dict.get(token)\n",
        "      if word_info is None:\n",
        "        wid.append(0)\n",
        "      else:\n",
        "        wid.append(word_info[0])\n",
        "\n",
        "  x = torch.tensor(np.asarray(wid))\n",
        "\n",
        "  num_batches = x.shape[0] // batch_size \n",
        "  x = x[:num_batches * batch_size]\n",
        "  x = x.view(batch_size, num_batches)  \n",
        "\n",
        "  return x\n",
        "\n",
        "def make_tensors(file_name,sequence_length):\n",
        "  '''\n",
        "  creates a list of tuples containing a list with the tokenized bio and a fake/real label\n",
        "\n",
        "  inputs: \n",
        "    file_name = a complete file path to a mixed dataset containing text and labels\n",
        "    sequence_length = the length of the desired input array\n",
        "  outputs:\n",
        "    x = a tensor containing wIDs of the desired sequence length for each bio\n",
        "    y = a tensor containing the corresponding label for each input\n",
        "  '''\n",
        "  \n",
        "  # stop = set(stopwords.words('english') + list(string.punctuation))\n",
        "\n",
        "\n",
        "  with open(file_name) as input:\n",
        "    all_text = input.readlines()\n",
        "\n",
        "# if anybody wants to do some work on the tokenization section, \n",
        "# you should work with the split_bios array, since it contains actual words\n",
        "\n",
        "# split_bios = [([bio1, tokens1],[REAL]),([bio2, tokens2],[FAKE])]\n",
        "  split_bios = []\n",
        "  line_text = []\n",
        "  seq_status = 0\n",
        "\n",
        "  # seq_status = 0 marks the start of the bio\n",
        "  # seq_status = 1 is the main text of the bio\n",
        "  # seq_status = 2 is the end of the bio\n",
        "  for line in all_text:\n",
        "    line = line.strip()\n",
        "    if \"< start_bio >\" in line:\n",
        "      seq_status = 0\n",
        "      continue\n",
        "    if \"< end_bio >\" in line:\n",
        "      seq_status = 2\n",
        "      line_text.append(line)\n",
        "      continue\n",
        "    if seq_status == 0:\n",
        "      # bio_person = line.strip(\" = \").lower().split()\n",
        "      # stop.update(bio_person) # could remove important words if name is meaningful\n",
        "      seq_status = 1\n",
        "    if seq_status == 1:\n",
        "      line = re.sub(\"[\\d-]\", \"\",line)\n",
        "      line = [token for token in word_tokenize(line.lower())]\n",
        "      # line = [token for token in word_tokenize(line.lower()) if token not in stop]\n",
        "      if len(line) > 0:\n",
        "        line_text.extend(line)\n",
        "    if seq_status == 2 and line !=\"\":\n",
        "      # stop -= set(bio_person)\n",
        "      # if line == '[FAKE]': #updated code so now fake / real is binary\n",
        "      #   line = 0\n",
        "      # elif line == '[REAL]':\n",
        "      #   line = 1\n",
        "      # else:\n",
        "      #   continue \n",
        "      split_bios.append((line_text,line))\n",
        "      line_text = []\n",
        "\n",
        "  encodings = read_encode(file_name,[],{},[],3)\n",
        "  word_dict = encodings[1]\n",
        "  vocab_length = max(encodings[2])\n",
        "\n",
        "  bio_array = []\n",
        "  seq_len = sequence_length\n",
        "  y = []\n",
        "\n",
        "  for bio in split_bios:\n",
        "    wid = []\n",
        "    for token in bio[0]:\n",
        "      word_info = word_dict.get(token)\n",
        "      if word_info is None:\n",
        "        wid.append(0)\n",
        "      else:\n",
        "        wid.append(word_info[0])\n",
        "    if len(wid) > seq_len:\n",
        "      wid = wid[:seq_len-2]\n",
        "      wid.append(word_dict.get('< end_bio >')[0]) #makes last token \"end bio\" no matter what\n",
        "      wid.append(word_dict.get(bio[1])[0])\n",
        "    # elif len(wid) < seq_len:\n",
        "    #   wid.append(word_dict.get(bio[1])[0])\n",
        "    #   pad_size = seq_len - len(wid)\n",
        "    #   wid.extend(np.ones(pad_size,dtype=int))\n",
        "    bio_array.append(np.asarray(wid))\n",
        "    y.append(word_dict.get(bio[1])[0])\n",
        "    # y.append(bio[1])\n",
        "\n",
        "  x = bio_array\n",
        "  y = torch.tensor(y)\n",
        "\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "S92xGxZAejT_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text = read_alltext('/content/NLP-DL-Group2/hw#1/mix.train.tok',300)"
      ],
      "metadata": {
        "id": "11k7TC1Bg8cm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data, seq_len, num_batches, idx):\n",
        "    src = data[:, idx:idx+seq_len]                   \n",
        "    target = data[:, idx+1:idx+seq_len+1]             \n",
        "    return src, target"
      ],
      "metadata": {
        "id": "DMmJcI2eVmzc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self, vocab, words,d_model, d_hidden, dropout):\n",
        "        super().__init__() \n",
        "    \n",
        "        self.vocab = vocab\n",
        "        self.words = words\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.d_model = d_model\n",
        "        self.d_hidden = d_hidden\n",
        "        self.dropout = dropout\n",
        "        self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
        "#          {perform other initializations needed for the FFNN}\n",
        "\n",
        "    def forward(self, src):\n",
        "        embeds = self.dropout(self.embeds(src))\n",
        "#          {add code to implement the FFNN}\n",
        "        pass\n",
        "        # return x\n",
        "                \n",
        "    def init_weights(self):\n",
        "      pass\n",
        "#          {perform initializations}\n",
        "             \n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self,vocab,words,d_model,d_hidden,n_layers,dropout_rate, tie_weights):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.words = words\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.n_layers = n_layers\n",
        "        self.d_hidden = d_hidden\n",
        "        self.d_model = d_model\n",
        "        self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
        "#          {perform other initializations needed for the LSTM}\n",
        "        self.lstm = nn.LSTM(2*d_model, d_hidden, n_layers, dropout=dropout_rate, bidirectional=True, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(2*d_hidden, self.vocab_size)\n",
        "\n",
        "        if tie_weights:\n",
        "          assert d_model == d_hidden, 'cannot tie, check dims'\n",
        "          self.embeds.weight = self.fc.weight\n",
        "        self.init_weights()\n",
        "        \n",
        "    def forward(self,src,h):\n",
        "        embeds = self.dropout(self.embeds(src)) \n",
        "        out, h = self.lstm(embeds, h)\n",
        "        out = self.dropout(out)\n",
        "        predict = self.fc(out)\n",
        "        return predict, h\n",
        "    \n",
        "    def init_weights(self):\n",
        "        emb_range = 0.1\n",
        "        init_range = 1/math.sqrt(self.d_hidden)\n",
        "        self.embeds.weight.data.uniform_(-emb_range, emb_range)\n",
        "        self.fc.weight.data.uniform_(-init_range, init_range)\n",
        "        self.fc.bias.data.zero_()\n",
        "        for i in range(self.n_layers):\n",
        "            self.lstm.all_weights[i][0] = torch.FloatTensor(self.d_model,\n",
        "                    self.d_hidden).uniform_(-init_range, init_range) \n",
        "            self.lstm.all_weights[i][1] = torch.FloatTensor(self.d_hidden, \n",
        "                    self.d_hidden).uniform_(-init_range, init_range) \n",
        "        \n",
        "    def init_hidden(self, batch_size, device):\n",
        "        hidden = torch.zeros(2*self.n_layers, batch_size, self.d_hidden).to(device)\n",
        "        cell = torch.zeros(2*self.n_layers, batch_size, self.d_hidden).to(device)\n",
        "        return hidden, cell\n",
        "\n",
        "    def detach_hidden(self, hidden):\n",
        "      hidden, cell = hidden\n",
        "      hidden = hidden.detach()\n",
        "      cell = cell.detach()\n",
        "      return hidden,cell\n",
        " \n",
        "def main():\n",
        "    \n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-d_model', type=int, default=100)\n",
        "    parser.add_argument('-d_hidden', type=int, default=100)\n",
        "    parser.add_argument('-n_layers', type=int, default=2)\n",
        "    parser.add_argument('-batch_size', type=int, default=20)\n",
        "    parser.add_argument('-seq_len', type=int, default=30)\n",
        "    parser.add_argument('-printevery', type=int, default=5000)\n",
        "    parser.add_argument('-window', type=int, default=3)\n",
        "    parser.add_argument('-epochs', type=int, default=20)\n",
        "    parser.add_argument('-lr', type=float, default=0.0001)\n",
        "    parser.add_argument('-dropout', type=int, default=0.35)\n",
        "    parser.add_argument('-clip', type=int, default=2.0)\n",
        "    parser.add_argument('-model', type=str,default='LSTM')\n",
        "    parser.add_argument('-savename', type=str,default='lstm')\n",
        "    parser.add_argument('-loadname', type=str)\n",
        "    parser.add_argument('-trainname', type=str,default='wiki.train.txt')\n",
        "    parser.add_argument('-validname', type=str,default='wiki.valid.txt')\n",
        "    parser.add_argument('-testname', type=str,default='wiki.test.txt')\n",
        "\n",
        "    params = {\n",
        "        'd_model': 512,\n",
        "        'd_hidden': 512,\n",
        "        'n_layers': 2,\n",
        "        'batch_size': 20,\n",
        "        'seq_len': 30,\n",
        "        'printevery': 500,\n",
        "        'window': 3,\n",
        "        'epochs': 20,\n",
        "        'lr': 0.0001,\n",
        "        'dropout': 0.35,\n",
        "        'clip': 2.0,\n",
        "        'model': 'LSTM',\n",
        "        'savename': 'lstm',\n",
        "        'loadname': None,\n",
        "        'trainname': '/content/NLP-DL-Group2/hw#1/mix.train.tok',\n",
        "        'validname': '/content/NLP-DL-Group2/hw#1/mix.valid.tok',\n",
        "        'testname': '/content/NLP-DL-Group2/hw#1/mix.test.tok'\n",
        "    }\n",
        "    parser.add_argument(\"-f\", required=False)\n",
        "    \n",
        "    # params = parser.parse_args()    \n",
        "    # torch.manual_seed(0)\n",
        "    \n",
        "    [vocab,words,train] = read_encode(params['trainname'],[],{},[],3)\n",
        "    print('vocab: %d train: %d' % (len(vocab),len(train)))\n",
        "    [vocab,words,test] = read_encode(params['testname'],vocab,words,[],-1)\n",
        "    print('vocab: %d test: %d' % (len(vocab),len(test)))\n",
        "    params['vocab_size'] = len(vocab)\n",
        "\n",
        "    train_loader = read_encode(params['trainname'],[],{},[],3)\n",
        "    \n",
        "    if params['model'] == 'FFNN':\n",
        "      pass\n",
        "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
        "        \n",
        "    if params['model'] == 'LSTM':\n",
        "      pass\n",
        "\n",
        "    if params['model'] == 'FFNN_CLASSIFY':\n",
        "      pass\n",
        "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n",
        "\n",
        "    if params['model'] == 'LSTM_CLASSIFY':\n",
        "      pass\n",
        "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n",
        "        \n",
        "    print(params)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwOAM-Ht6WMu",
        "outputId": "8325bd70-1c3e-48be-8752-fe1b3c667cac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab: 35153 train: 3012820\n",
            "vocab: 35153 test: 395279\n",
            "{'d_model': 512, 'd_hidden': 512, 'n_layers': 2, 'batch_size': 20, 'seq_len': 30, 'printevery': 500, 'window': 3, 'epochs': 20, 'lr': 0.0001, 'dropout': 0.35, 'clip': 2.0, 'model': 'LSTM', 'savename': 'lstm', 'loadname': None, 'trainname': '/content/NLP-DL-Group2/hw#1/mix.train.tok', 'validname': '/content/NLP-DL-Group2/hw#1/mix.valid.tok', 'testname': '/content/NLP-DL-Group2/hw#1/mix.test.tok', 'vocab_size': 35153}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[vocab,words,train] = read_encode('/content/NLP-DL-Group2/hw#1/mix.train.tok',[],{},[],3)\n",
        "\n",
        "rmv_list = []\n",
        "\n",
        "for key,value in words.items():\n",
        "  if value[1] < 10:\n",
        "    rmv_list.append(value[0])\n",
        "\n",
        "print(len(rmv_list))\n",
        "\n",
        "updated_vocab = list(set(train) - set(rmv_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LgE9a7my2BJ",
        "outputId": "c02baa05-bb24-454c-bb5e-9abe4dc70f8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(updated_vocab))\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "id": "Ysi5yQfs0MNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[vocab,words,train] = read_encode('/content/NLP-DL-Group2/hw#1/mix.train.tok',[],{},[],3)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "data = all_text\n",
        "batch_size = 20\n",
        "seq_len = 30\n",
        "clip = 2.0\n",
        "\n",
        "model = LSTM(vocab,words,512,512,2,.35,True) \n",
        "optimizer = optim.Adam(model.parameters(), lr=.0008)\n",
        "\n",
        "def LSTM_train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  num_batches = data.shape[-1]\n",
        "  data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "  num_batches = data.shape[-1]\n",
        "\n",
        "  hidden = model.init_hidden(batch_size, device)\n",
        "    \n",
        "  for idx in range(0, num_batches - 1, seq_len):  # The last batch can't be a src\n",
        "      optimizer.zero_grad()\n",
        "      hidden = model.detach_hidden(hidden)\n",
        "\n",
        "      src, target = get_batch(data, seq_len, num_batches, idx)\n",
        "      src, target = src.to(device), target.to(device)\n",
        "      batch_size = src.shape[0]\n",
        "      prediction, hidden = model(src, hidden)               \n",
        "\n",
        "      prediction = prediction.reshape(batch_size * seq_len, -1)   \n",
        "      target = target.reshape(-1)\n",
        "      loss = criterion(prediction, target)\n",
        "      \n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item() * seq_len\n",
        "    \n",
        "  return math.exp(epoch_loss / num_batches)\n",
        "\n",
        "# print(LSTM_train(model,data,optimizer,criterion,batch_size,seq_len,clip,device))"
      ],
      "metadata": {
        "id": "UhLLoJRoVxfx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data, criterion, batch_size, seq_len, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    num_batches = data.shape[-1]\n",
        "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "    num_batches = data.shape[-1]\n",
        "\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, num_batches - 1, seq_len):\n",
        "            hidden = model.detach_hidden(hidden)\n",
        "            src, target = get_batch(data, seq_len, num_batches, idx)\n",
        "            src, target = src.to(device), target.to(device)\n",
        "            batch_size= src.shape[0]\n",
        "\n",
        "            prediction, hidden = model(src, hidden)\n",
        "            prediction = prediction.reshape(batch_size * seq_len, -1)\n",
        "            target = target.reshape(-1)\n",
        "\n",
        "            loss = criterion(prediction, target)\n",
        "            epoch_loss += loss.item() * seq_len\n",
        "    return math.exp(epoch_loss / num_batches)"
      ],
      "metadata": {
        "id": "pZCzdNJeQOXp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50 \n",
        "saved = True\n",
        "\n",
        "train_data = read_alltext('/content/NLP-DL-Group2/hw#1/mix.train.tok',20)\n",
        "valid_data = read_alltext('/content/NLP-DL-Group2/hw#1/mix.valid.tok',20)\n",
        "test_data = read_alltext('/content/NLP-DL-Group2/hw#1/mix.test.tok',20)\n",
        "\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "aIBd96mQPexA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    model.load_state_dict(torch.load('best-val-lstm_lm.pt',  map_location=device))\n",
        "    test_loss = evaluate(model, test_data, criterion, batch_size, seq_len, device)\n",
        "    print(f'Test Perplexity: {test_loss:.3f}')\n",
        "else:\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = LSTM_train(model, train_data, optimizer, criterion, \n",
        "                    20, seq_len, clip, device)\n",
        "        valid_loss = evaluate(model, valid_data, criterion, 20, \n",
        "                    seq_len, device)\n",
        "        \n",
        "        lr_scheduler.step(valid_loss)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'best-val-lstm_lm.pt')\n",
        "\n",
        "        print(f'\\tTrain Perplexity: {train_loss:.3f}')\n",
        "        print(f'\\tValid Perplexity: {valid_loss:.3f}')"
      ],
      "metadata": {
        "id": "WT-rYeNiRfqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.tensor(word_tensors[0][0]).reshape(-1,1)\n",
        "# print(input.reshape(-1,1))\n",
        "\n",
        "def LSTM_Classify(input, model, vocab, device, seed=None):\n",
        "  if seed is not None:\n",
        "      torch.manual_seed(seed)\n",
        "  model.eval()\n",
        "  batch_size = len(input)\n",
        "  hidden = model.init_hidden(batch_size, device)\n",
        "  with torch.no_grad():\n",
        "      src = input\n",
        "      prediction, hidden = model(src, hidden)\n",
        "      probs = torch.softmax(prediction[:, -1] , dim=-1)  \n",
        "      real_prediction = probs[-1][638]\n",
        "      fake_prediction = probs[-1][125]\n",
        "      if real_prediction > fake_prediction:\n",
        "        prediction = 638\n",
        "      else:\n",
        "        prediction = 125\n",
        "\n",
        "  return prediction\n",
        "\n",
        "LSTM_Classify(input,model,vocab,device)"
      ],
      "metadata": {
        "id": "7Y7A_zgdXpiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(word_tensors[1]))\n",
        "\n",
        "correct = 0\n",
        "\n",
        "for index in range(len(word_tensors[1])):\n",
        "  item = torch.tensor(word_tensors[0][index]).reshape(-1,1)\n",
        "  prediction = LSTM_Classify(item,model,vocab,device)\n",
        "  actual = word_tensors[1][index]\n",
        "  if prediction == actual:\n",
        "    correct += 1\n",
        "  \n",
        "print(correct/len(word_tensors[1]))"
      ],
      "metadata": {
        "id": "4OO9-tp822wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(vocab,words,params['d_model'],params['d_hidden'],params['n_layers'],params['dropout']) \n",
        "optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "data = word_tensors\n",
        "y_data = torch.cat((word_tensors[0],word_tensors[1].reshape(-1,1)),1)[:params['seq_len'],1:513]\n",
        "tie_weights = True\n",
        "# hidden = model.init_weights(10)"
      ],
      "metadata": {
        "id": "Fsc1FTzGWBML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop = set(stopwords.words('english') + list(string.punctuation))"
      ],
      "metadata": {
        "id": "LYnopIlVDnnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "hidden = model.detach_hidden(hidden)\n",
        "\n",
        "src = data[0][:10]\n",
        "target = torch.cat((word_tensors[0],word_tensors[1].reshape(-1,1)),1)[1:513,:10]\n",
        "src, target = src.to(device), target.to(device)\n",
        "prediction, hidden = model(src, hidden)\n",
        "\n",
        "prediction = prediction.reshape(-1)\n",
        "target = target.reshape(-1)\n",
        "print(prediction.size())\n",
        "print(target.size())\n",
        "loss = loss(prediction,target)\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "epoch_loss += loss.item() * 10\n",
        "\n",
        "print(epoch_loss)"
      ],
      "metadata": {
        "id": "c9G7kEl0r96w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}