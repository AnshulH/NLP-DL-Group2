{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnshulH/NLP-DL-Group2/blob/lstm/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi1PuVNx4ao-",
        "outputId": "39f9fc60-37d9-4fb5-82ac-a7e4183801f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP-DL-Group2'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 120 (delta 35), reused 18 (delta 5), pack-reused 46\u001b[K\n",
            "Receiving objects: 100% (120/120), 30.93 MiB | 18.04 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r /content/NLP-DL-Group2/\n",
        "!cd /content && git clone https://github.com/AnshulH/NLP-DL-Group2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xI8qgF_4quC",
        "outputId": "ae53c19a-db86-48c9-e62f-7f4452ad0ef0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words # added for detecting English words\n",
        "import string\n",
        "import nltk\n",
        "import calendar\n",
        "import re\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlVZH18a4u2F",
        "outputId": "873be7fc-6788-44bc-8644-7019a0c7b683"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(0)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVK7KgCM41qR"
      },
      "outputs": [],
      "source": [
        "def decode(vocab,corpus):\n",
        "    \n",
        "    text = ''\n",
        "    for i in range(len(corpus)):\n",
        "        wID = corpus[i]\n",
        "        text = text + vocab[wID] + ' '\n",
        "    return(text)\n",
        "\n",
        "def encode(words,text):\n",
        "    corpus = []\n",
        "    tokens = text.split(' ')\n",
        "    for t in tokens:\n",
        "        try:\n",
        "            wID = words[t][0]\n",
        "        except:\n",
        "            wID = words['<unk>'][0]\n",
        "        corpus.append(wID)\n",
        "    return(corpus)\n",
        "\n",
        "def read_encode(file_name,vocab,words,corpus,threshold):\n",
        "    \n",
        "    wID = len(vocab)\n",
        "    if threshold > -1:\n",
        "        with open(file_name,'rt') as f:\n",
        "            for line in f:\n",
        "                line = line.replace('\\n','')\n",
        "                tokens = line.split(' ')\n",
        "                for t in tokens:\n",
        "                    try:\n",
        "                        elem = words[t]\n",
        "                    except:\n",
        "                        elem = [wID,0]\n",
        "                        vocab.append(t)\n",
        "                        wID = wID + 1\n",
        "                    elem[1] = elem[1] + 1\n",
        "                    words[t] = elem\n",
        "\n",
        "        temp = words\n",
        "        words = {}\n",
        "        vocab = []\n",
        "        wID = 0\n",
        "        words['<unk>'] = [wID,100]\n",
        "        wID = 1\n",
        "        words['< start_bio >'] = [wID,100]\n",
        "        wID = 2\n",
        "        words['< end_bio >'] = [wID,100]\n",
        "        vocab.append('<unk>')\n",
        "        vocab.append('< start_bio >')\n",
        "        vocab.append('< end_bio >')\n",
        "        for t in temp:\n",
        "            if temp[t][1] >= threshold:\n",
        "                vocab.append(t)\n",
        "                wID = wID + 1\n",
        "                words[t] = [wID,temp[t][1]]\n",
        "            \n",
        "                    \n",
        "    with open(file_name,'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.replace('\\n','')\n",
        "            tokens = line.split(' ')\n",
        "            for t in tokens:\n",
        "                try:\n",
        "                    wID = words[t][0]\n",
        "                except:\n",
        "                    wID = words['<unk>'][0]\n",
        "                corpus.append(wID)\n",
        "                \n",
        "    return [vocab,words,corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1676oxmG6HBE"
      },
      "outputs": [],
      "source": [
        "def read_alltext(file_name,batch_size,vocab,words):\n",
        "  '''\n",
        "  tokenizes data, removes digits, converts to wIDs, and provides a tensor of batched inputs\n",
        "  inputs: \n",
        "    file_name = a complete file path to a mixed dataset containing text and labels\n",
        "    sequence_length = the length of the desired input array\n",
        "  outputs:\n",
        "    x = a tensor containing wIDs of the input\n",
        "  '''\n",
        "  word_dict = words\n",
        "  wid = []\n",
        "  real_wid = word_dict.get('[REAL]')[0]\n",
        "  fake_wid = word_dict.get('[FAKE]')[0]\n",
        "\n",
        "  with open(file_name) as input:\n",
        "    all_text = input.readlines()\n",
        "\n",
        "  for line in all_text:\n",
        "    line = line.strip()\n",
        "    line = re.sub(\"[\\d-]\", \"\",line)\n",
        "    if \"< start_bio >\" in line:\n",
        "      try:\n",
        "        wid.append(1)\n",
        "      except:\n",
        "        continue\n",
        "    elif \"< end_bio >\" in line:\n",
        "        wid.append(2)\n",
        "    elif \"[REAL]\" in line:\n",
        "        wid.append(real_wid)\n",
        "    elif \"[FAKE]\" in line:\n",
        "        wid.append(fake_wid)\n",
        "    else:\n",
        "      line = [token for token in word_tokenize(line.lower())]\n",
        "      for token in line:\n",
        "        word_info = word_dict.get(token)\n",
        "        if word_info is None:\n",
        "          wid.append(0) \n",
        "        else:\n",
        "          wid.append(word_info[0])\n",
        "\n",
        "  x = torch.tensor(np.asarray(wid)) \n",
        "  num_batches = x.shape[0] // batch_size \n",
        "  x = x[:num_batches * batch_size] \n",
        "  x = x.view(batch_size, num_batches)   \n",
        "\n",
        "  return x,vocab,words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIwsL4kA6Uwf"
      },
      "outputs": [],
      "source": [
        "def get_batch(data, seq_len, num_batches, idx):\n",
        "    src = data[:, idx:idx+seq_len]                   \n",
        "    target = data[:, idx+1:idx+seq_len+1]             \n",
        "    return src, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVgf4Udu6dmX",
        "outputId": "ecd6eb3b-8e11-47a1-ea1d-6d900eb1d68c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab: 35152 train: 3012820\n",
            "vocab: 35152 test: 395279\n",
            "{'d_model': 512, 'd_hidden': 512, 'n_layers': 2, 'batch_size': 20, 'seq_len': 30, 'printevery': 500, 'window': 3, 'epochs': 20, 'lr': 0.0001, 'dropout': 0.35, 'clip': 2.0, 'model': 'LSTM', 'savename': 'lstm', 'loadname': None, 'trainname': '/content/NLP-DL-Group2/hw#1/mix.train.tok', 'validname': '/content/NLP-DL-Group2/hw#1/mix.valid.tok', 'testname': '/content/NLP-DL-Group2/hw#1/mix.test.tok', 'vocab_size': 35152}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self, vocab, words,d_model, d_hidden, dropout):\n",
        "        super().__init__() \n",
        "    \n",
        "        self.vocab = vocab\n",
        "        self.words = words\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.d_model = d_model\n",
        "        self.d_hidden = d_hidden\n",
        "        self.dropout = dropout\n",
        "        self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
        "#          {perform other initializations needed for the FFNN}\n",
        "\n",
        "    def forward(self, src):\n",
        "        embeds = self.dropout(self.embeds(src))\n",
        "#          {add code to implement the FFNN}\n",
        "        pass\n",
        "        # return x\n",
        "                \n",
        "    def init_weights(self):\n",
        "        pass\n",
        "#          {perform initializations}\n",
        "             \n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self,vocab,words,d_model,d_hidden,n_layers,dropout_rate, tie_weights):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.words = words\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.n_layers = n_layers\n",
        "        self.d_hidden = d_hidden\n",
        "        self.d_model = d_model\n",
        "        self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
        "#          {perform other initializations needed for the LSTM}\n",
        "        self.lstm = nn.LSTM(d_model, d_hidden, n_layers, dropout=dropout_rate, bidirectional=False, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(d_hidden, self.vocab_size)\n",
        "\n",
        "        if tie_weights:\n",
        "          assert d_model == d_hidden, 'cannot tie, check dims'\n",
        "          self.embeds.weight = self.fc.weight\n",
        "        self.init_weights()\n",
        "        \n",
        "    def forward(self,src,h):\n",
        "        embeds = self.dropout(self.embeds(src))  \n",
        "        out, h = self.lstm(embeds, h) \n",
        "        out = self.dropout(out)\n",
        "        predict = self.fc(out) \n",
        "        return predict, h\n",
        "    \n",
        "    def init_weights(self):\n",
        "        emb_range = 0.1\n",
        "        init_range = 1/math.sqrt(self.d_hidden)\n",
        "        self.embeds.weight.data.uniform_(-emb_range, emb_range)\n",
        "        self.fc.weight.data.uniform_(-init_range, init_range)\n",
        "        self.fc.bias.data.zero_()\n",
        "        for i in range(self.n_layers):\n",
        "            self.lstm.all_weights[i][0] = torch.FloatTensor(self.d_model,\n",
        "                    self.d_hidden).uniform_(-init_range, init_range) \n",
        "            self.lstm.all_weights[i][1] = torch.FloatTensor(self.d_hidden, \n",
        "                    self.d_hidden).uniform_(-init_range, init_range) \n",
        "        \n",
        "    def init_hidden(self, batch_size, device):\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.d_hidden).to(device)\n",
        "        cell = torch.zeros(self.n_layers, batch_size, self.d_hidden).to(device)\n",
        "        return hidden, cell\n",
        "\n",
        "    def detach_hidden(self, hidden):\n",
        "      hidden, cell = hidden\n",
        "      hidden = hidden.detach()\n",
        "      cell = cell.detach()\n",
        "      return hidden,cell\n",
        " \n",
        "def main():\n",
        "    \n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-d_model', type=int, default=100)\n",
        "    parser.add_argument('-d_hidden', type=int, default=100)\n",
        "    parser.add_argument('-n_layers', type=int, default=2)\n",
        "    parser.add_argument('-batch_size', type=int, default=20)\n",
        "    parser.add_argument('-seq_len', type=int, default=30)\n",
        "    parser.add_argument('-printevery', type=int, default=5000)\n",
        "    parser.add_argument('-window', type=int, default=3)\n",
        "    parser.add_argument('-epochs', type=int, default=20)\n",
        "    parser.add_argument('-lr', type=float, default=0.0001)\n",
        "    parser.add_argument('-dropout', type=int, default=0.35)\n",
        "    parser.add_argument('-clip', type=int, default=2.0)\n",
        "    parser.add_argument('-model', type=str,default='LSTM')\n",
        "    parser.add_argument('-savename', type=str,default='lstm')\n",
        "    parser.add_argument('-loadname', type=str)\n",
        "    parser.add_argument('-trainname', type=str,default='wiki.train.txt')\n",
        "    parser.add_argument('-validname', type=str,default='wiki.valid.txt')\n",
        "    parser.add_argument('-testname', type=str,default='wiki.test.txt')\n",
        "\n",
        "    params = {\n",
        "        'd_model': 512,\n",
        "        'd_hidden': 512,\n",
        "        'n_layers': 2,\n",
        "        'batch_size': 20,\n",
        "        'seq_len': 30,\n",
        "        'printevery': 500,\n",
        "        'window': 3,\n",
        "        'epochs': 20,\n",
        "        'lr': 0.0001,\n",
        "        'dropout': 0.35,\n",
        "        'clip': 2.0,\n",
        "        'model': 'LSTM',\n",
        "        'savename': 'lstm',\n",
        "        'loadname': None,\n",
        "        'trainname': '/content/NLP-DL-Group2/hw#1/mix.train.tok',\n",
        "        'validname': '/content/NLP-DL-Group2/hw#1/mix.valid.tok',\n",
        "        'testname': '/content/NLP-DL-Group2/hw#1/mix.test.tok'\n",
        "    }\n",
        "    parser.add_argument(\"-f\", required=False)\n",
        "    \n",
        "    # params = parser.parse_args()    \n",
        "    # torch.manual_seed(0)\n",
        "    \n",
        "    [vocab,words,train] = read_encode(params['trainname'],[],{},[],3)\n",
        "    print('vocab: %d train: %d' % (len(vocab),len(train)))\n",
        "    [vocab,words,test] = read_encode(params['testname'],vocab,words,[],-1)\n",
        "    print('vocab: %d test: %d' % (len(vocab),len(test)))\n",
        "    params['vocab_size'] = len(vocab)\n",
        "\n",
        "    train_loader = read_encode(params['trainname'],[],{},[],3)\n",
        "    \n",
        "    if params['model'] == 'FFNN':\n",
        "      pass\n",
        "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
        "        \n",
        "    if params['model'] == 'LSTM':\n",
        "      pass\n",
        "\n",
        "    if params['model'] == 'FFNN_CLASSIFY':\n",
        "      pass\n",
        "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n",
        "\n",
        "    if params['model'] == 'LSTM_CLASSIFY':\n",
        "      pass\n",
        "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n",
        "        \n",
        "    print(params)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K5EiF8S6ite"
      },
      "outputs": [],
      "source": [
        "def LSTM_train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  num_batches = data.shape[-1]\n",
        "  data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "  num_batches = data.shape[-1]\n",
        "\n",
        "  hidden = model.init_hidden(batch_size, device)\n",
        "    \n",
        "  for idx in range(0, num_batches - 1, seq_len):  # The last batch can't be a src\n",
        "      optimizer.zero_grad()\n",
        "      hidden = model.detach_hidden(hidden)\n",
        "\n",
        "      src, target = get_batch(data, seq_len, num_batches, idx)\n",
        "      src, target = src.to(device), target.to(device)\n",
        "      batch_size = src.shape[0]\n",
        "      prediction, hidden = model(src, hidden)               \n",
        "\n",
        "      prediction = prediction.reshape(batch_size * seq_len, -1)   \n",
        "      target = target.reshape(-1)\n",
        "      loss = criterion(prediction, target)\n",
        "      \n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item() * seq_len\n",
        "    \n",
        "  return math.exp(epoch_loss / num_batches)\n",
        "  \n",
        "# [vocab,words,train] = read_encode('/content/NLP-DL-Group2/hw#1/mix.train.tok',[],{},[],3)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# data = all_text\n",
        "# batch_size = 20\n",
        "# seq_len = 30\n",
        "# clip = 2.0\n",
        "\n",
        "# model = LSTM(vocab,words,512,512,2,.35,True) \n",
        "# optimizer = optim.Adam(model.parameters(), lr=.0008)\n",
        "# print(LSTM_train(model,data,optimizer,criterion,batch_size,seq_len,clip,device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xD4tXuu46k06"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data, criterion, batch_size, seq_len, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    num_batches = data.shape[-1]\n",
        "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "    num_batches = data.shape[-1]\n",
        "\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, num_batches - 1, seq_len):\n",
        "            hidden = model.detach_hidden(hidden)\n",
        "            src, target = get_batch(data, seq_len, num_batches, idx)\n",
        "            src, target = src.to(device), target.to(device)\n",
        "            batch_size= src.shape[0]\n",
        "\n",
        "            prediction, hidden = model(src, hidden)\n",
        "            prediction = prediction.reshape(batch_size * seq_len, -1)\n",
        "            target = target.reshape(-1)\n",
        "\n",
        "            loss = criterion(prediction, target)\n",
        "            epoch_loss += loss.item() * seq_len\n",
        "    return math.exp(epoch_loss / num_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kUrI0LU6qA9"
      },
      "outputs": [],
      "source": [
        "encodings = read_encode('/content/NLP-DL-Group2/hw#1/mix.train.tok',[],{},[],3) \n",
        "train_data,vocab,words = read_alltext('/content/NLP-DL-Group2/hw#1/mix.train.tok',20,encodings[0],encodings[1])\n",
        "valid_data,vocab,words = read_alltext('/content/NLP-DL-Group2/hw#1/mix.valid.tok',20,vocab,words)\n",
        "test_data,vocab,words = read_alltext('/content/NLP-DL-Group2/hw#1/mix.test.tok',20,vocab,words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7BkRyR96mqU"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss() \n",
        "batch_size = 20\n",
        "seq_len = 30\n",
        "clip = 2.0\n",
        "n_epochs = 25\n",
        "saved = True\n",
        "\n",
        "model = LSTM(vocab,words,512,512,2,.35,True).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=.0008)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2vhnRbzWXLC"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=.0008)\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTqV4ykk6sza",
        "outputId": "8b3b89f8-d44a-4454-bc0a-7cbbc5e146b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Perplexity: 179.475\n",
            "\tValid Perplexity: 66.991\n",
            "\tTrain Perplexity: 73.545\n",
            "\tValid Perplexity: 49.944\n",
            "\tTrain Perplexity: 56.900\n",
            "\tValid Perplexity: 43.796\n",
            "\tTrain Perplexity: 48.883\n",
            "\tValid Perplexity: 40.910\n",
            "\tTrain Perplexity: 43.876\n",
            "\tValid Perplexity: 39.106\n",
            "\tTrain Perplexity: 40.472\n",
            "\tValid Perplexity: 37.886\n",
            "\tTrain Perplexity: 38.008\n",
            "\tValid Perplexity: 37.348\n",
            "\tTrain Perplexity: 36.095\n",
            "\tValid Perplexity: 36.881\n",
            "\tTrain Perplexity: 34.562\n",
            "\tValid Perplexity: 36.562\n",
            "\tTrain Perplexity: 33.369\n",
            "\tValid Perplexity: 36.475\n",
            "\tTrain Perplexity: 32.383\n",
            "\tValid Perplexity: 36.277\n",
            "\tTrain Perplexity: 31.519\n",
            "\tValid Perplexity: 36.230\n",
            "\tTrain Perplexity: 30.808\n",
            "\tValid Perplexity: 36.198\n",
            "\tTrain Perplexity: 30.158\n",
            "\tValid Perplexity: 36.093\n",
            "\tTrain Perplexity: 29.618\n",
            "\tValid Perplexity: 36.174\n",
            "\tTrain Perplexity: 27.475\n",
            "\tValid Perplexity: 35.457\n",
            "\tTrain Perplexity: 26.755\n",
            "\tValid Perplexity: 35.341\n",
            "\tTrain Perplexity: 26.308\n",
            "\tValid Perplexity: 35.298\n",
            "\tTrain Perplexity: 25.941\n",
            "\tValid Perplexity: 35.282\n",
            "\tTrain Perplexity: 25.676\n",
            "\tValid Perplexity: 35.257\n",
            "\tTrain Perplexity: 25.336\n",
            "\tValid Perplexity: 35.290\n",
            "\tTrain Perplexity: 24.495\n",
            "\tValid Perplexity: 34.974\n",
            "\tTrain Perplexity: 24.184\n",
            "\tValid Perplexity: 34.907\n",
            "\tTrain Perplexity: 23.957\n",
            "\tValid Perplexity: 34.864\n",
            "\tTrain Perplexity: 23.754\n",
            "\tValid Perplexity: 34.842\n"
          ]
        }
      ],
      "source": [
        "train = []\n",
        "valid = []\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = LSTM_train(model, train_data, optimizer, criterion, \n",
        "                20, seq_len, clip, device)\n",
        "    valid_loss = evaluate(model, valid_data, criterion, 20, \n",
        "                seq_len, device)\n",
        "    \n",
        "    lr_scheduler.step(valid_loss)\n",
        "\n",
        "    print(f'\\tTrain Perplexity: {train_loss:.3f}')\n",
        "    print(f'\\tValid Perplexity: {valid_loss:.3f}')\n",
        "\n",
        "    train.append(train_loss)\n",
        "    valid.append(valid_loss)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best-val-lstm_lm.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BVaGb8ACjnvp",
        "outputId": "bdc9ae12-0b50-47f2-9794-0ea1f6903fb4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1VklEQVR4nO3deXxU1f3/8dcnM8lMVhJCwpYgoICC7BG02gpqrXXDWm3lZ1uoVivtT7/aRbvYYluptvXXxbbar61rtVK1SrXuO1brgigIiAUBJYBkwezrZD6/P+7NMITJPkuS+Twfj3nMnTN3zjkzA/POucu5oqoYY4wxACmJ7oAxxpiBw0LBGGNMiIWCMcaYEAsFY4wxIRYKxhhjQiwUjDHGhFgomKgTkcdFZEm0100kEdkhIifFoN4XRORr7vL5IvJUT9btQzvjRKRORDx97atJDhYKBgD3B6P9FhSRxrDH5/emLlX9rKreGe11ByIR+Z6IrI5QPkJEWkTkyJ7Wpar3qOrJUerXASGmqh+qapaqtkWj/g5tqYgcFu16TWJYKBgA3B+MLFXNAj4Ezggru6d9PRHxJq6XA9LdwCdEZEKH8vOAd1R1QwL6ZEyfWSiYLonIAhEpFZGrROQj4HYRyRORf4lIuYh87C4Xhb0mfJPIUhH5t4jc4K67XUQ+28d1J4jIahGpFZFnROSPInJ3J/3uSR9/JiIvu/U9JSIjwp7/soh8ICKVIvLDzj4fVS0FngO+3OGprwB3ddePDn1eKiL/Dnv8aRHZLCLVIvIHQMKeO1REnnP7VyEi94hIrvvcX4FxwCPuSO9KERnv/kXvddcZIyIPi8g+EdkqIheF1X2NiNwnIne5n81GESnp7DPojIgMc+sodz/Lq0UkxX3uMBF50X1vFSLyd7dcROQ3IlImIjUi8k5vRlum/ywUTE+MAoYDhwAX4/y7ud19PA5oBP7QxevnA+8BI4BfAreKiPRh3b8BrwP5wDUc/EMcrid9/D/AV4FCIA34DoCITAVudusf47YX8YfcdWd4X0RkCjDL7W9vP6v2OkYADwJX43wW7wPHhq8CXOf27wigGOczQVW/zIGjvV9GaGIlUOq+/hzg5yJyQtjzZ7rr5AIP96TPEfweGAZMBI7HCcqvus/9DHgKyMP5bH/vlp8MfAqY7L72C0BlH9o2faWqdrPbATdgB3CSu7wAaAH8Xaw/C/g47PELwNfc5aXA1rDnMgAFRvVmXZwf1ACQEfb83cDdPXxPkfp4ddjjbwBPuMs/BlaGPZfpfgYndVJ3BlADfMJ9vAL4Zx8/q3+7y18BXg1bT3B+xL/WSb1nAW9F+g7dx+Pdz9KLEyBtQHbY89cBd7jL1wDPhD03FWjs4rNV4LAOZR73M5saVvZ14AV3+S7gFqCow+tOAP4LHA2kJPr/QjLebKRgeqJcVZvaH4hIhoj8r7tJoAZYDeRK50e2fNS+oKoN7mJWL9cdA+wLKwPY2VmHe9jHj8KWG8L6NCa8blWtp4u/Vt0+3Q98xR3VnI/zo9eXz6pdxz5o+GMRGSkiK0Vkl1vv3Tgjip5o/yxrw8o+AMaGPe742fild/uTRgCpbr2R2rgSJ+hedzdPXQCgqs/hjEr+CJSJyC0iktOLdk0/WSiYnug4le63gSnAfFXNwRnuQ9g27xjYAwwXkYywsuIu1u9PH/eE1+22md/Na+7E2dTxaSAbeKSf/ejYB+HA9/tznO9lulvvlzrU2dX0x7txPsvssLJxwK5u+tQbFUArzmazg9pQ1Y9U9SJVHYMzgrhJ3COYVPVGVZ2LM0KZDHw3iv0y3bBQMH2RjbNtvEpEhgPLY92gqn4ArAGuEZE0ETkGOCNGfXwAOF1EjhORNOCndP9/5SWgCmeTyEpVbelnPx4FponI2e5f6JfhbEZrlw3UAdUiMpaDfzj34mzLP4iq7gReAa4TEb+IzAAuxBlt9FWaW5dfRPxu2X3AChHJFpFDgG+1tyEi54btcP8YJ8SCInKUiMwXkVSgHmgCgv3ol+klCwXTF78F0nH+GnwVeCJO7Z4PHIOzKeda4O9Acyfr/pY+9lFVNwLfxNlRvAfnR6u0m9coziajQ9z7fvVDVSuAc4Hrcd7vJODlsFV+AswBqnEC5MEOVVwHXC0iVSLynQhNLMbZz7AbeAhYrqrP9KRvndiIE37tt68Cl+L8sG8D/o3zed7mrn8U8JqI1OHsyP4fVd0G5AB/xvnMP8B577/qR79ML4m7c8eYQcc9jHGzqsZ8pGJMsrCRghk03E0Lh4pIioicAiwCViW4W8YMKXZ2qhlMRuFsJsnH2ZyzTFXfSmyXjBlabPORMcaYENt8ZIwxJmRQbz4aMWKEjh8/PtHdMMaYQeXNN9+sUNWCSM8N6lAYP348a9asSXQ3jDFmUBGRDzp7zjYfGWOMCbFQMMYYE2KhYIwxJmRQ71MwxsRHa2srpaWlNDU1db+yGTD8fj9FRUWkpqb2+DUxCwURuQ04HShT1SPdslnAnwA/ztz431DV190ZIH8HnIozTe9SVV0bq74ZY3qntLSU7Oxsxo8fT+fXRzIDiapSWVlJaWkpEyZ0vFps52K5+egO4JQOZb8EfqKqs3AuZNJ+RajP4kz4NQnnyl43x7BfxpheampqIj8/3wJhEBER8vPzez26i1koqOpqYF/HYpxZEMG51N5ud3kRcJc6XsW5CMnoWPXNGNN7FgiDT1++s3jvaL4c+JWI7ARuAL7vlo/lwKtolXLgVaCiavNHNfzqyc1UNbR0v7IxxiSReIfCMuAKVS0GrgBu7W0FInKxiKwRkTXl5eV96sQHlQ388fn3Kf24sU+vN8bEV2VlJbNmzWLWrFmMGjWKsWPHhh63tHT9x92aNWu47LLLum3jE5/4RFT6+sILL3D66adHpa5EiPfRR0uA/3GX7wf+4i7v4sBLDRbRyaUBVfUWnKtbUVJS0qfZ/AqyfQCU13Z2fRZjzECSn5/P22+/DcA111xDVlYW3/nO/msHBQIBvN7IP2clJSWUlJR028Yrr7wSlb4OdvEeKewGjneXTwC2uMsP4170XESOBqpVdU+sOlGQZaFgzGC3dOlSLrnkEubPn8+VV17J66+/zjHHHMPs2bP5xCc+wXvvvQcc+Jf7NddcwwUXXMCCBQuYOHEiN954Y6i+rKys0PoLFizgnHPO4fDDD+f888+nfTbpxx57jMMPP5y5c+dy2WWX9WpEcO+99zJ9+nSOPPJIrrrqKgDa2tpYunQpRx55JNOnT+c3v/kNADfeeCNTp05lxowZnHfeef3/sHohloek3gssAEaISCnOtWkvAn7nXnO2CedII4DHcA5H3YpzSOpXY9UvCBsp1FkoGNNbP3lkI5t210S1zqljclh+xrRev660tJRXXnkFj8dDTU0NL730El6vl2eeeYYf/OAH/OMf/zjoNZs3b+b555+ntraWKVOmsGzZsoOO43/rrbfYuHEjY8aM4dhjj+Xll1+mpKSEr3/966xevZoJEyawePHiHvdz9+7dXHXVVbz55pvk5eVx8skns2rVKoqLi9m1axcbNmwAoKqqCoDrr7+e7du34/P5QmXxErNQUNXOPrG5EdZVnGvixoU/1UOO32sjBWMGuXPPPRePxwNAdXU1S5YsYcuWLYgIra2tEV9z2mmn4fP58Pl8FBYWsnfvXoqKig5YZ968eaGyWbNmsWPHDrKyspg4cWLomP/Fixdzyy239Kifb7zxBgsWLKCgwJmY9Pzzz2f16tX86Ec/Ytu2bVx66aWcdtppnHzyyQDMmDGD888/n7POOouzzjqr159LfyTtGc0F2T4LBWP6oC9/0cdKZmZmaPlHP/oRCxcu5KGHHmLHjh0sWLAg4mt8Pl9o2ePxEAgE+rRONOTl5bFu3TqefPJJ/vSnP3Hfffdx22238eijj7J69WoeeeQRVqxYwTvvvNPpPpNoS9q5jywUjBlaqqurGTvWOZL9jjvuiHr9U6ZMYdu2bezYsQOAv//97z1+7bx583jxxRepqKigra2Ne++9l+OPP56KigqCwSCf//znufbaa1m7di3BYJCdO3eycOFCfvGLX1BdXU1dXV3U309nknik4Oed0qpEd8MYEyVXXnklS5Ys4dprr+W0006Lev3p6encdNNNnHLKKWRmZnLUUUd1uu6zzz57wCap+++/n+uvv56FCxeiqpx22mksWrSIdevW8dWvfpVgMAjAddddR1tbG1/60peorq5GVbnsssvIzc2N+vvpzKC+RnNJSYn29SI7P31kE39/40M2/rTjTBzGmI7effddjjjiiER3I+Hq6urIyspCVfnmN7/JpEmTuOKKKxLdrS5F+u5E5E1VjXicblJvPqpvaaO+OTbbCo0xQ8+f//xnZs2axbRp06iurubrX/96orsUdUm8+cjZkVRR10ymL2k/BmNML1xxxRUDfmTQX0k9UgA7gc0YY8IlbSgUWigYY8xBkjYU7KxmY4w5WNKGQl5GGp4UoazGQsEYY9olbSh4UoT8zDTbfGTMILBw4UKefPLJA8p++9vfsmzZsk5fs2DBAtoPWT/11FMjziF0zTXXcMMNN3TZ9qpVq9i0aVPo8Y9//GOeeeaZXvQ+soE6xXbShgK4ZzXb5iNjBrzFixezcuXKA8pWrlzZ40npHnvssT6fANYxFH76059y0kkn9amuwcBCwUYKxgx455xzDo8++mjogjo7duxg9+7dfPKTn2TZsmWUlJQwbdo0li9fHvH148ePp6KiAoAVK1YwefJkjjvuuND02uCcg3DUUUcxc+ZMPv/5z9PQ0MArr7zCww8/zHe/+11mzZrF+++/z9KlS3nggQcA58zl2bNnM336dC644AKam5tD7S1fvpw5c+Ywffp0Nm/e3OP3mugptpP6AP2CLB+b99QmuhvGDC6Pfw8+eie6dY6aDp+9vtOnhw8fzrx583j88cdZtGgRK1eu5Atf+AIiwooVKxg+fDhtbW2ceOKJrF+/nhkzZkSs580332TlypW8/fbbBAIB5syZw9y5zsTNZ599NhdddBEAV199NbfeeiuXXnopZ555JqeffjrnnHPOAXU1NTWxdOlSnn32WSZPnsxXvvIVbr75Zi6//HIARowYwdq1a7npppu44YYb+Mtf/kJ3BsIU20k9UijM8VFR10wwOHin+jAmWYRvQgrfdHTfffcxZ84cZs+ezcaNGw/Y1NPRSy+9xOc+9zkyMjLIycnhzDPPDD23YcMGPvnJTzJ9+nTuueceNm7c2GV/3nvvPSZMmMDkyZMBWLJkCatXrw49f/bZZwMwd+7c0CR63QmfYtvr9Yam2J44cWJoiu0nnniCnJwcYP8U23fffXfUZlFN+pFCIKhUNbYyPDMt0d0xZnDo4i/6WFq0aBFXXHEFa9eupaGhgblz57J9+3ZuuOEG3njjDfLy8li6dClNTU19qn/p0qWsWrWKmTNncscdd/DCCy/0q7/t029HY+rteE6xndQjhYJsPwBltX37R2SMiZ+srCwWLlzIBRdcEBol1NTUkJmZybBhw9i7dy+PP/54l3V86lOfYtWqVTQ2NlJbW8sjjzwSeq62tpbRo0fT2trKPffcEyrPzs6mtvbgzcxTpkxhx44dbN26FYC//vWvHH/88Qet1xsDYYrtWF6O8zbgdKBMVY8MK78U5yprbcCjqnqlW/594EK3/DJVffLgWqMrfKqLw0fFujVjTH8tXryYz33uc6HNSDNnzmT27NkcfvjhFBcXc+yxx3b5+jlz5vDFL36RmTNnUlhYeMD01z/72c+YP38+BQUFzJ8/PxQE5513HhdddBE33nhjaAczgN/v5/bbb+fcc88lEAhw1FFHcckll/Tq/QzEKbZjNnW2iHwKqAPuag8FEVkI/BA4TVWbRaRQVctEZCpwLzAPGAM8A0xW1bau2ujP1NkA2yvqWXjDC/z6CzM5e05R9y8wJknZ1NmD14CZOltVVwP7OhQvA65X1WZ3nTK3fBGwUlWbVXU7sBUnIGLKJsUzxpgDxXufwmTgkyLymoi8KCLtY7exwM6w9UrdsoOIyMUiskZE1pSXl/erM5lpHtJTPRYKxhjjincoeIHhwNHAd4H7RER6U4Gq3qKqJapaUlBQ0K/OiAiFOXZWszE9MZiv0pis+vKdxTsUSoEH1fE6EARGALuA4rD1ityymCvIsrOajemO3++nsrLSgmEQUVUqKyvx+/29el28z1NYBSwEnheRyUAaUAE8DPxNRH6Ns6N5EvB6PDpUkO1jS1n/D+MyZigrKiqitLSU/m6yNfHl9/sPOLqpJ2J5SOq9wAJghIiUAsuB24DbRGQD0AIsUedPj40ich+wCQgA3+zuyKNoKcj28cr7lfFoyphBKzU1lQkTJiS6GyYOYhYKqtrZ9IVf6mT9FcCKWPWnMwVZPqobW2kOtOHzeuLdvDHGDChJfUYz7D8staKuJcE9McaYxLNQsHMVjDEmJOlDodCd/8hCwRhjLBRCIwWbFM8YYywUyM9ypsy2kYIxxlgokOpJYXhmmoWCMcZgoQDYWc3GGNPOQgFnv4LNf2SMMRYKgBsKNlIwxhgLBYBCNxRssi9jTLKzUMAZKTQHgtQ09e/i2sYYM9hZKGBnNRtjTDsLBZyjj8BCwRhjLBQIGynYEUjGmCRnoYBtPjLGmHYWCsCw9FTSPCkWCsaYpBezUBCR20SkzL3KWsfnvi0iKiIj3MciIjeKyFYRWS8ic2LVr076aucqGGMMsR0p3AGc0rFQRIqBk4EPw4o/i3Nd5knAxcDNMexXRCOyfTZTqjEm6cUsFFR1NbAvwlO/Aa4Ews8UWwTcpY5XgVwRGR2rvkVi8x8ZY0yc9ymIyCJgl6qu6/DUWGBn2ONStyxSHReLyBoRWVNeXh61vhVk+6iwo4+MMUkubqEgIhnAD4Af96ceVb1FVUtUtaSgoCA6ncMJhcr6FgJtwajVaYwxg008RwqHAhOAdSKyAygC1orIKGAXUBy2bpFbFjcF2T5UYV99SzybNcaYASVuoaCq76hqoaqOV9XxOJuI5qjqR8DDwFfco5COBqpVdU+8+gb7z2ous/0KxpgkFstDUu8F/gNMEZFSEbmwi9UfA7YBW4E/A9+IVb86Y2c1G2MMeGNVsaou7ub58WHLCnwzVn3picL2UKixUDDGJC87o9llIwVjjLFQCPGnesj2e+1cBWNMUrNQCGNTXRhjkp2FQhg7q9kYk+wsFMIUZPtsn4IxJqlZKISxzUfGmGRnoRCmMNtPXXOAhpZAortijDEJYaEQxq7AZoxJdhYKYSwUjDHJzkIhTPv8RxYKxphkZaEQxs5qNsYkOwuFMMMz00gRGykYY5KXhUIYT4qQn+WjzCbFM8YkKQuFDgrtBDZjTBKzUOjATmAzxiQzC4UObP4jY0wys1DooCDbR0VdM8GgJrorxhgTd7G8HOdtIlImIhvCyn4lIptFZL2IPCQiuWHPfV9EtorIeyLymVj1qzsF2T4CQaWqsTVRXTDGmISJ5UjhDuCUDmVPA0eq6gzgv8D3AURkKnAeMM19zU0i4olh3zplZzUbY5JZzEJBVVcD+zqUPaWq7bPNvQoUucuLgJWq2qyq24GtwLxY9a0r7Wc1l9U2JaJ5Y4xJqETuU7gAeNxdHgvsDHuu1C07iIhcLCJrRGRNeXl51DtVmOMHbKRgjElOCQkFEfkhEADu6e1rVfUWVS1R1ZKCgoKo9802Hxljkpk33g2KyFLgdOBEVW0/xGcXUBy2WpFbFneZaR7SUz0WCsaYpBTXkYKInAJcCZypqg1hTz0MnCciPhGZAEwCXo9n38L6aJflNMYkrZiNFETkXmABMEJESoHlOEcb+YCnRQTgVVW9RFU3ish9wCaczUrfVNW2WPWtO3ZWszEmWcUsFFR1cYTiW7tYfwWwIlb96Y2CLB/vl9cluhvGGBN3dkZzBAXZPspspGCMSUIWChEUZvuobmylOZCwLVjGGJMQFgoRtB+WWlHXkuCeGGNMfFkoRGDnKhhjkpWFQgQWCsaYZGWhEIGFgjEmWVkoRJCfaaFgjElOFgoRpHlTyMtItZlSjTFJx0KhE4XZfhspGGOSTo9CQUQyRSTFXZ4sImeKSGpsu5ZYNv+RMSYZ9XSksBrwi8hY4CngyzhXVhuybP4jY0wy6mkoiDur6dnATap6Ls6lM4es9lDYP7u3McYMfT0OBRE5BjgfeNQtS8g1lOOlIMtHcyBIbXOg+5WNMWaI6GkoXI4z7fVD7jTXE4HnY9arAcDOVTDGJKMeTZ2tqi8CLwK4O5wrVPWyWHYs0dpDoaymmUMLshLcG2OMiY+eHn30NxHJEZFMYAOwSUS+G9uuJVZopGBHIBljkkhPNx9NVdUa4CzgcWACzhFInRKR20SkTEQ2hJUNF5GnRWSLe5/nlouI3CgiW0VkvYjM6dvbiZ5C23xkjElCPQ2FVPe8hLOAh1W1FejusJw7gFM6lH0PeFZVJwHPuo8BPotzXeZJwMXAzT3sV8wMS08l1SMWCsaYpNLTUPhfYAeQCawWkUOAmq5eoKqrgX0dihcBd7rLd+KETHv5Xep4FcgVkdE97FtMiAgFWXaugjEmufQoFFT1RlUdq6qnuj/cHwAL+9DeSFXd4y5/BIx0l8cCO8PWK3XLDiIiF4vIGhFZU15e3ocu9Jyd1WyMSTY93dE8TER+3f5jLCL/D2fU0GfqnBXW6zPDVPUWVS1R1ZKCgoL+dKFbBdk+ympsUjxjTPLo6eaj24Ba4AvurQa4vQ/t7W3fLOTel7nlu4DisPWK3LKEKsj2UWEjBWNMEulpKByqqstVdZt7+wkwsQ/tPQwscZeXAP8MK/+KexTS0UB12GamhCnI8lFZ30KgLZjorhhjTFz0NBQaReS49gcicizQ2NULRORe4D/AFBEpFZELgeuBT4vIFuAk9zHAY8A2YCvwZ+AbvXoXMVKQ40cV9tW3JLorxhgTFz06oxm4BLhLRIa5jz9m/1/8Eanq4k6eOjHCugp8s4d9iZuCLPes5tpmCnP8Ce6NMcbEXk+nuVgHzBSRHPdxjYhcDqyPYd8Szs5qNsYkm15deU1Va9wzmwG+FYP+DCh2VrMxJtn053KcErVeDFAjsiwUjDHJpT+hMOSvPpOe5iHb57VQMMYkjS73KYhILZF//AVIj0mPBhi7LKcxJpl0GQqqmh2vjgxUFgrGmGTSn81HScHmPzLGJBMLhW7YSMEYk0wsFLpRkO2jrjlAQ0sg0V0xxpiYs1DoRoEdlmqMSSIWCt0osBPYjDFJxEKhGxYKxphkYqHQjcJsZyI8OwLJGJMMLBS6MTwzjRSxkYIxJjlYKHTDkyLkZ9lhqcaY5GCh0AMFFgrGmCSRkFAQkStEZKOIbBCRe0XELyITROQ1EdkqIn8XkbRE9C2SgmwfZRYKxpgkEPdQEJGxwGVAiaoeCXiA84BfAL9R1cNwrux2Ybz71hk7q9kYkywStfnIC6SLiBfIAPYAJwAPuM/fCZyVmK4drCDbR0VdM8HgkJ8t3BiT5OIeCqq6C7gB+BAnDKqBN4EqVW2fS6IUGBvvvnWmMNtHIKhUNbYmuivGGBNTidh8lAcsAiYAY4BM4JRevP5iEVkjImvKy8tj1MsD2QlsxphkkYjNRycB21W1XFVbgQeBY4Fcd3MSQBGwK9KLVfUWVS1R1ZKCgoK4dNjmPzLGJItEhMKHwNEikiEiApwIbAKeB85x11kC/DMBfYsoNFKoa0pwT4wxJrYSsU/hNZwdymuBd9w+3AJcBXxLRLYC+cCt8e5bZ9pDoazGRgrGmKGty8txxoqqLgeWdyjeBsxLQHe6leXz4k9Nsc1Hxpghz85o7gERsctyGmOSgoVCDxVm+22kYIwZ8iwUeqgw28f2inpa24KJ7ooxxsSMhUIPnT2niD3VTdzx8o5Ed8UYY2LGQqGHTjqikBMOL+S3z/yXvTV2aKoxZmiyUOghEWH5GVNpDSorHn030d0xxpiYsFDohUPyM7nk+EN5eN1u/vN+ZaK7Y4wxUWeh0EvfWHAoRXnp/PifG2ynszFmyLFQ6CV/qodrzpjGlrI62+lsjBlyLBT64KSpI22nszFmSErOUPjgFfjLSdD4cZ+rsJ3OxpihKDlDIS0TStfAC7/ocxWH5GeyzN3p/Mr7FVHsnDHGJE5yhsLomTB3Kbx+C5T1/S/9ZQsOpXh4Osv/udF2OhtjhoTkDAWAE34Evix4/CrQvl172Z/qYfnpttPZGDN0JG8oZObDwqth+4vw7iN9ruakqSM50XY6G2OGiOQNBYCSC6BwKjz5Q2ht7HM1y8+YZjudjTFDQnKHgscLn/0FVH8IL9/Y52rG5WfYTmdjzJCQkFAQkVwReUBENovIuyJyjIgMF5GnRWSLe58Xl85M+BRMPQv+/Wuo+rDP1dhOZ2PMUJCokcLvgCdU9XBgJvAu8D3gWVWdBDzrPo6Pk38GCDz1oz5XYTudjTFDQdxDQUSGAZ8CbgVQ1RZVrQIWAXe6q90JnBW3TuWOg+OugE2rYPvqPldjO52NMYNdIkYKE4By4HYReUtE/iIimcBIVd3jrvMRMDLSi0XkYhFZIyJrysvLo9erYy+DYeOcQ1TbAn2uxnY6G2MGs0SEgheYA9ysqrOBejpsKlJVBSKePKCqt6hqiaqWFBQURK9XqenwmRVQtgnW3NbnamynszFmMEtEKJQCpar6mvv4AZyQ2CsiowHc+7K49+yIM2DC8fD8tVDf9+sl2E5nY8xgFfdQUNWPgJ0iMsUtOhHYBDwMLHHLlgD/jHffEHEOUW2ug+d+1udqwqfX/ukjmwhYMBhjBolEHX10KXCPiKwHZgE/B64HPi0iW4CT3MfxV3gEzLsY3rwD9qzrczUnHjGSC4+bwF9f/YClt7/Bx/Ut0eujMcbEiGgf5/0ZCEpKSnTNmjXRr7ixCn4/B/InwQVPOCOIPrpvzU6ufmgDI4f5+N8vlTB1TE70+mmMMX0gIm+qakmk55L7jObOpOfCicth56vwzgP9quoLJcX8/etH0xII8vmbX+Ff63dHp4/GGBMDFgqdmf1lGDMbnv6Rs4+hP1WNy+ORS49j2pgc/u/f3uL6xzfTFhy8IzRjzNBlodCZlBT47C+hdg+89P/6XV1htp+/XXQ0588fx59efJ+v3vEGVQ22n8EYM7BYKHSleB7MXAz/+QNUvt/v6tK8Kaz43HSuO3s6/3m/gjP/8DKbP6qJQkeNMSY6LBS6c9I14ElzpteOksXzxrHy4mNoam3j7Jte4bF39nT/ImOMiQMLhe5kj4Ljr4T/Pg5bno5atXMPcfYzHD4qm2/cs5ZfPWn7GYwxiWeh0BPzl0H+YfDQJbD+/j5fvrOjkTl+7r34aBbPK+aPz7/PhXe+QXVja1TqNsaYvrBQ6AlvGnzxHmc21Qe/BnctgoqtUana5/Vw3dkzWPG5I3l5awWL/vBvnt60l8F8/ogxZvCyUOipwsPha8/AqTfA7rfh5mPg+Z9Da3SmyD5//iHce9HRKHDRXWs44w//5hkLB2NMnNkZzX1Ruxee+iG8cz/kTYDTboDDTopK1YG2IA+9tYvfP7eVD/c1cOTYHC4/cTInHlGI9OPMamOMadfVGc0WCv2x7QV49NtQuRWmfQ4+cx3kjI5K1a1tQVaFhcP0scO4/KRJnHC4hYMxpn8sFGIp0Awv/w5W3+AcunrC1TDvIkjxRKX61tDIYQs79zUyo8gJh4VTLByMMX1joRAPle/DY9+B95+D0TPh9N/A2LlRq761LchDa3fx++ctHIwx/WOhEC+qsPEheOL7ULcXSi6AT30HcsZErYmO4TCzaBjLFhzGwsML8HmjMzoxxgxtFgrx1lQDz6+A128BDcLI6TDp0zDpZCg6CjzefjfR2hbkwbWl/P65rZR+3Ei238tnpo3i9BmjOfawEaR67MAyY0xkFgqJUrEVNv/LORP6w/+AtoF/GBx6ohMQh50EWf27znRrW5B/b6ngkfW7eXrjXmqbA+RlpHLKkaM5Y8Zo5k/Mx5Nim5eMMfsNyFAQEQ+wBtilqqeLyARgJZAPvAl8WVW7nEZ0wIdCuMYq52ilLU/Dlqeg3r0E9Zg5TkBM+rQzVXc/dlA3tbbx4n/L+df6PTz77l4aWtoYkeXj1OmjOGPmGOaOyyPFAsKYpDdQQ+FbQAmQ44bCfcCDqrpSRP4ErFPVm7uqY1CFQrhgED5avz8gSt8AFDLy4dATnHAYeaRzy8zvUxONLW08t7mMf63fzXOby2gOBBmV4+e0GaM5fcZoZhXn2g5qY5LUgAsFESkC7gRWAN8CzgDKgVGqGhCRY4BrVPUzXdUzaEOho/pK56ilLU85o4n2UQRA1igYdSSMnOYGxTQYMRk8qT2uvq45wLPv7uWRdbt58b/ltLYp+ZlpzJ84nPkT8pk/cTiTC7NtFGFMkhiIofAAcB2QDXwHWAq8qqqHuc8XA4+r6pERXnsxcDHAuHHj5n7wwQfx6nb81JXB3g2wd6Nz+2gDlG+GoDtZXkoqFBzuBsU0Zzl3HOQWQ1pml1VXN7byzKa9vLy1gte272NXVSMAeRmpHDV+OEdPdELiiFE5FhLGDFEDKhRE5HTgVFX9hogsoJehEG7IjBR6oq0VKra4QbFhf2jUdrgWQ0Y+DCt2AmLYuP1h0V7mz4WwzUY79zXw2vZ9vLatkle3V7JznxMSOX4v8ybsH0lMHZ2D145oMmZI6CoU+n9sZO8dC5wpIqcCfiAH+B2QKyJeVQ0ARcCuBPRt4PKkwsipzo1z95fXV0LlFqjaCdUfOvdVH0L5e7DlGQg0HliPL8cJiMx8SMum2OfczsnLhlFZVAX9bK0WNlUqb+9p4+HNwt9IR9OyKB5VyGFjC5g2No9pY3I4rDDLDn01ZohJ6CGp7SMFd0fz/cA/wnY0r1fVm7p6fVKNFPpCFRoqoeoDNzR27g+Nxo+huRZaap375loIBnpUbb36aMBPA37avBmk+LJITc8mI2sY2TnD8Pqznc1YaZng9YHX796nd3jsh1T/gY9TUkFSnNGMpDhHY0lKh5vHfd42bxnTFwNtpNCZq4CVInIt8BZwa4L7M/iJQOYI59bdlBuqEGiC5jportkfFC117nINtNQTbK6jpbqK+uqPqautprm+lkBDLb66vWSUf0CDNJMtzWRIE16N9QWD3ODwpDph4vG696mQ4u2kPDUsaMStI+xeUiKUucsQ+TWEB1RYWUp7eHnC2vQcGHTh5ZLinOwY8aYRytqcoE3Pc24ZwyE9F9KH7y/zD7PwNL2S0FBQ1ReAF9zlbcC8RPYnqYlAarpz6+KEuhQgz721U1X2VDexcXcNG3dXs3F3DZt21/BRVR1ptOKnhYyUABNyvUzM8zB+mJdxOSkU56QwOlPI9rYhgSYnlIIB5wcw2Hbgj1/4j2Gwww9jW6vzurZWZ2d8W8C9j/Q44LTT/iOLulfS0w5ldCjj4HXD750P4uDngm37+x9a7qTc+SIijIzCb2EjKMQN8pouvlePGxR5bljkOhM3hgLJE3af0uGxp8OoTOg0TLsLSjouhpd1WO+gEG7/XCIsd/X5H1SG857CR6YHjWA7PucPC/eUsD8aOnwf4Z/NIA/hgTRSMIOUiDAmN50xuel8eurIUHlNUyvby+t5v7yObeX1bKuo47WyelZ+UE9LIBhab1i6j4kFBRxakMW44RmMzU1nTH46RXnpjBrmT579Fqp9+0Fpa3VOjmz8OOy2b/9yQ9hyXZmzvrbtD6Ngh3AK3YcHcqTgjPAjbFx9DdKw10PXATnv63D8d6PecwsFEzM5/lRmFucyszj3gPK2oLK7qpGtblg4oVHH6v+WU1bbfMC6IjAy28/YPCd0xuamMzbXeTw2N4MxuX6y/T0/Z2NA6+tfmJ5UZ3TXzylTokIj/aUeerIHZXrgcui5Tpa72nwXqSwYgLZmZ8r7QNOB962NEcqbOt+Eh3Z4Tjs8112QQuejmx58FoWHd/VN9JmFgok7T4pQPDyD4uEZLJxy4HNNrW3srmpkd1UTu6oa2FXVxK6PG9ld1ci6nVU8sWEPrW0H/lWakeahMNtHYbafwpz99yPbl93nctK9dhZ3rA34zSdpQEaiOzGgWSiYAcWf6mFiQRYTC7IiPh8MKuV1zZS6QbG7qpG9Nc2U1TZRVtvMhl3VlNWW0dDSdtBrfd4UCnN8FGT5GJHlIz/Lx4isNPIz0xiR7SM/032c5SM3PdVO3jNJyULBDCopKcLIHD8jc/zMPSSv0/XqmgPsrWmizA2M8tpm53FtM2U1zXxQ2cDaDz9mX30LwQibwz0pwvBMNzCyfORlppGbnkpuRiq5GeHL+x8PS0+1E/zMoGehYIakLJ+XrIIsDu1kxNGuLah83NBCZV0LlXXNVNQ795V1LVTWN1NR10JFXTO7qhqpamihurE1Yoi0y/Z5GeaGxbD0/bccfyo57cuhMu/+59NTk2eHuhnQLBRMUvOkCCPczUnOVFxdCwaV2qYAVY0tVDW0UtXYSlWDu9zQSlVjC9UNrXzsBsjemmaqG1upbmw94IirSDLSPE6Y+bxk+b2dLme795lpXoryMpg8MstGKCZqLBSM6YWUFGFYRirDMlI5pJezmje1tlHT2EpNU2soKGoaA2HLrdS3BKhtClDXHKCuKcCH9Q3OcrNT3hZhmJKe6mF60TBmF+cyqziXWeNyGT0sPUrv2CQbCwVj4sSf6sGf6qEwx9+n16sqzYFgKDRqm1rZVl7P2zureGtnFbe/vIOWNmc0MjLH5wREcR6zinOZXjSMLJ/9dzfds38lxgwSIhIKloJsHwAzinI5a/ZYAJoDbWzaXcPbO6tYt7OKt3dW8eTGvQCkCEwqzGZm8TBGD0snr30HediO8ryMNLL9XjvqKslZKBgzRPi8HmaPy2P2uP1HZX1c38LbpVW8/aETEs++W0ZlfedXuU0RGJYeFhjujvAMn5fMNA/paV4y0jyhZefeQ6bPS3qqc5/hlvm9HlI9YueGDDIWCsYMYXmZaSycUsjCKYWhskBbkJqmAFUNLXzc0Ep1Ywsf13fYae4uV9S1sLW8jsaWNhrcW2+kiLPPwx+6peBP9YSVpYSeS/OmkOZJwedNCS2nuvdpYWXh9+11+LxhdXk9+FKdeiyQes9CwZgk4/WkMDwzjeGZab1+bTCoNAXaqG9uo7GljfqWgBsW++/rm9toam2/BWl0lxtb22huDYaWG1oC7KsPhtZtDgRpaQvS4t5HY1Z/n9cJh/bgyfJ5yXdPWBye6SM/K40RWfuX8zOdkxcz0zxJGygWCsaYHktJETLSvGSkxfanQ1UJBJXW9pAIBEOh0V7WHAiGQqY54IZLwA2egBNIzYG2A9apaWylsr6FDyobqKxrpr6TkU+aN4URmWkMz0ojI83rhsv+EYjP63HuU8OWvSn4Uj343FGM1yOketwRjyeFVI+Q6k0hNSWFVO+Bz3k9Eir3pqQkdLObhYIxZsAREedH1JNCRu8HND3W1NpGZX0L++paqKh3TlrcV99+8qJzImNjaxt1zQEq61qckAkF0v7lWPCkCN4UIc0NDa8nhdQU994jLJ43jq99cmLU27VQMMYkLX+qx515t+/ndagqLW0HjlzCRzmtbUHncWik4zzXGmE54K7bEggSCAYJtKlTHtz/fGtbkNagho5AizYLBWOM6QcRcTcheZyrzg9ycT83XkSKReR5EdkkIhtF5H/c8uEi8rSIbHHvO5/tzBhjTEwkYsKUAPBtVZ0KHA18U0SmAt8DnlXVScCz7mNjjDFxFPdQUNU9qrrWXa4F3gXGAouAO93V7gTOinffjDEm2SV0akURGQ/MBl4DRqrqHvepj4CRnbzmYhFZIyJrysvL49NRY4xJEgkLBRHJAv4BXK6qNeHPqXZ+JXBVvUVVS1S1pKBgAFyT1hhjhpCEhIKIpOIEwj2q+qBbvFdERrvPjwbKEtE3Y4xJZok4+kiAW4F3VfXXYU89DCxxl5cA/4x334wxJtkl4jyFY4EvA++IyNtu2Q+A64H7RORC4APgCwnomzHGJDXRaMw6lSAiUo4TIAAjgIoYNzlU2ohXO/ZeBl4b8WpnqLQRr3bi9V7aHaKqEXfKDupQCCcia1S1xNoYOO3Yexl4bcSrnaHSRrzaidd76Qm72rcxxpgQCwVjjDEhQykUbrE2Blw79l4GXhvxameotBGvduL1Xro1ZPYpGGOM6b+hNFIwxhjTTxYKxhhjQgZ9KIjIKSLynohsFZGYTLfd2TUgYtSWR0TeEpF/xaj+XBF5QEQ2i8i7InJMjNq5wv2sNojIvSLS78uPiMhtIlImIhvCyqJ+HY5O2vmV+5mtF5GHRCQ32m2EPfdtEVERGRGLNkTkUve9bBSRX/anjc7aEZFZIvKqiLztTmA5r59txPw6LF20Ee3vvsvfk2h9/32mqoP2BniA94GJQBqwDpgag3ZGA3Pc5Wzgv7Fox63/W8DfgH/FqP47ga+5y2lAbgzaGAtsB9Ldx/cBS6NQ76eAOcCGsLJfAt9zl78H/CJG7ZwMeN3lX/S3nUhtuOXFwJM4J2WOiMH7WAg8A/jcx4Ux+ryeAj7rLp8KvNDPNiL+H4zm999FG9H+7jv9PYnm99/X22AfKcwDtqrqNlVtAVbiXJchqrTza0BElYgUAacBf4l23W79w3D+A98KoKotqloVi7ZwplBJFxEvkAHs7m+Fqroa2NehOOrX4YjUjqo+paoB9+GrQFG023D9BriSTmYJjkIby4DrVbXZXaffE0920o4COe7yMPr5/XfxfzBq339nbcTgu+/q9yRq339fDfZQGAvsDHtcSgx+rMN1uAZEtP0W5x9EMAZ1A0wAyoHb3U1UfxGRzGg3oqq7gBuAD4E9QLWqPhXtdlw9ug5HlF0APB7tSkVkEbBLVddFu+4wk4FPishrIvKiiBwVo3YuB34lIjtx/i18P1oV9+U6LP1sI1xUv/vwduL0/XdrsIdCXHV1DYgo1H06UKaqb0az3g68OMP8m1V1NlBPDC576m7XXYQTQmOATBH5UrTb6Uid8XdM/8ISkR/iXFL2nijXm4EzMeSPo1lvBF5gOM6lcL+LMwmlxKCdZcAVqloMXIE7Ou2vrv4PRuv776yNaH/34e249cbj++/WYA+FXTjb4NoVuWVRJ5GvARFNxwJnisgOnM1gJ4jI3VFuoxQoVdX2v34ewAmJaDsJ2K6q5araCjwIfCIG7UAcr8MhIkuB04Hz3R+gaDoUJ0TXuf8GioC1IjIqyu2UAg+q43WcUWksdmguwfneAe7H2dTbL538H4zq99/Z//Nof/cR2onX99+twR4KbwCTRGSCiKQB5+FclyGq3L+kIl0DImpU9fuqWqSq43Hex3OqGtW/rlX1I2CniExxi04ENkWzDdeHwNEikuF+difibDeNhbhch0NETsHZtHemqjZEu35VfUdVC1V1vPtvoBRnZ+RHUW5qFc7OZkRkMs7BBrGYnXM3cLy7fAKwpT+VdfF/MGrff2dtRPu7j9ROHL//7iVi73Y0bzhHNvwX5yikH8aojeNwhqXrgbfd26kxfE8LiN3RR7OANe57WQXkxaidnwCbgQ3AX3GPdulnnffi7KNoxflPcyGQDzyL86PzDDA8Ru1sxdl/1f79/ynabXR4fgf9P/oo0vtIA+52v5e1wAkx+ryOA97EOSLwNWBuP9uI+H8wmt9/F21E+7vv9vckGt9/X282zYUxxpiQwb75yBhjTBRZKBhjjAmxUDDGGBNioWCMMSbEQsEYY0yIhYIxEYhImzvDZ/stamd+i8j4SLOjGjMQeBPdAWMGqEZVnZXoThgTbzZSMKYXRGSHiPxSRN4RkddF5DC3fLyIPOfOuf+siIxzy0e6c/Cvc2/t0314ROTP7nz6T4lIurv+Ze48++tFZGWC3qZJYhYKxkSW3mHz0RfDnqtW1enAH3BmtgX4PXCnqs7AmTDtRrf8RuBFVZ2JM8/URrd8EvBHVZ0GVAGfd8u/B8x267kkNm/NmM7ZGc3GRCAidaqaFaF8B87UENvcSc0+UtV8EakARqtqq1u+R1VHiEg5UKTu9QvcOsYDT6vqJPfxVUCqql4rIk8AdThTkKxS1boYv1VjDmAjBWN6TztZ7o3msOU29u/fOw34I86o4g33IkXGxI2FgjG998Ww+/+4y6/gzG4LcD7wkrv8LM61Bdqvvz2ss0pFJAUoVtXngatwrlh20GjFmFiyv0KMiSxdRN4Oe/yEqrYflponIutx/tpf7JZdinNFu+/iXN3uq275/wC3iMiFOCOCZTgzikbiAe52g0OAGzV2l0s1JiLbp2BML7j7FEpUNRbXIDAm4WzzkTHGmBAbKRhjjAmxkYIxxpgQCwVjjDEhFgrGGGNCLBSMMcaEWCgYY4wJ+f9BiP3YlK3h6wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib.pylab import plt\n",
        "from numpy import arange\n",
        "\n",
        "# Generate a sequence of integers to represent the epoch numbers\n",
        "epochs = range(1, 26)\n",
        " \n",
        "# Plot and label the training and validation loss values\n",
        "plt.plot(epochs, train , label='Training Loss')\n",
        "plt.plot(epochs, valid, label='Validation Loss')\n",
        " \n",
        "# Add in a title and axes labels\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        " \n",
        "# Set the tick locations\n",
        "plt.xticks(arange(0, 26, 2))\n",
        " \n",
        "# Display the plot\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15jJMSEYeAx0"
      },
      "outputs": [],
      "source": [
        "# save code\n",
        "torch.save({\n",
        "            'epoch': 10,\n",
        "            'batch': 20,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(), \n",
        "            }, \"/content/drive/My Drive/lstm_mixed.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OQqmo5Uedwg",
        "outputId": "27e79a7e-6480-44e3-c4a0-d5e79ba92d86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Perplexity: 35.324\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/lstm_mixed.pt',  map_location=device)['model_state_dict'])\n",
        "test_loss = evaluate(model, test_data, criterion, batch_size, seq_len, device)\n",
        "print(f'Test Perplexity: {test_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn_p9F6s6Ru-"
      },
      "outputs": [],
      "source": [
        "def make_tensors(file_name,vocab,words):\n",
        "  '''\n",
        "  creates a list of tuples containing a list with the tokenized bio and a fake/real label\n",
        "\n",
        "  inputs: \n",
        "    file_name = a complete file path to a mixed dataset containing text and labels \n",
        "  outputs:\n",
        "    x = a tensor containing wIDs for each bio\n",
        "    y = a tensor containing the corresponding label for each input\n",
        "  '''\n",
        "  \n",
        "  # stop = set(stopwords.words('english') + list(string.punctuation))\n",
        "  with open(file_name) as input:\n",
        "    all_text = input.readlines()\n",
        "\n",
        "# if anybody wants to do some work on the tokenization section, \n",
        "# you should work with the split_bios array, since it contains actual words\n",
        "\n",
        "# split_bios = [([bio1, tokens1],[REAL]),([bio2, tokens2],[FAKE])]\n",
        "  split_bios = []\n",
        "  line_text = []\n",
        "  seq_status = 0\n",
        "\n",
        "  # seq_status = 0 marks the start of the bio\n",
        "  # seq_status = 1 is the main text of the bio\n",
        "  # seq_status = 2 is the end of the bio\n",
        "  for line in all_text:\n",
        "    line = line.strip()\n",
        "    if \"< start_bio >\" in line:\n",
        "      seq_status = 0\n",
        "      continue\n",
        "    if \"< end_bio >\" in line:\n",
        "      seq_status = 2\n",
        "      line_text.append(line)\n",
        "      continue\n",
        "    if seq_status == 0:\n",
        "      # bio_person = line.strip(\" = \").lower().split()\n",
        "      # stop.update(bio_person) # could remove important words if name is meaningful\n",
        "      seq_status = 1\n",
        "    if seq_status == 1:\n",
        "      line = re.sub(\"[\\d-]\", \"\",line)\n",
        "      line = [token for token in word_tokenize(line.lower())]\n",
        "      # line = [token for token in word_tokenize(line.lower()) if token not in stop]\n",
        "      if len(line) > 0:\n",
        "        line_text.extend(line)\n",
        "    if seq_status == 2 and line !=\"\":\n",
        "      # stop -= set(bio_person)\n",
        "      # if line == '[FAKE]': #updated code so now fake / real is binary\n",
        "      #   line = 0\n",
        "      # elif line == '[REAL]':\n",
        "      #   line = 1\n",
        "      # else:\n",
        "      #   continue  \n",
        "      split_bios.append((line_text,line))\n",
        "      line_text = []\n",
        " \n",
        "  word_dict = words  \n",
        "  bio_array = [] \n",
        "  y = []\n",
        "\n",
        "  for bio in split_bios:\n",
        "    wid = []\n",
        "    wid.append(1)\n",
        "    for token in bio[0]:\n",
        "      word_info = word_dict.get(token)\n",
        "      if word_info is None:\n",
        "        wid.append(0)\n",
        "      else:\n",
        "        wid.append(word_info[0])\n",
        "    # if len(wid) > seq_len:\n",
        "    #   wid = wid[:seq_len-2]\n",
        "    #   wid.append(word_dict.get('< end_bio >')[0]) #makes last token \"end bio\" no matter what\n",
        "    #   wid.append(word_dict.get(bio[1])[0])\n",
        "    # elif len(wid) < seq_len:\n",
        "    #   wid.append(word_dict.get(bio[1])[0])\n",
        "    #   pad_size = seq_len - len(wid)\n",
        "    #   wid.extend(np.ones(pad_size,dtype=int))\n",
        "    bio_array.append(np.asarray(wid)) \n",
        "    real_wid = word_dict.get('[REAL]')[0]\n",
        "    fake_wid = word_dict.get('[FAKE]')[0] \n",
        "    if real_wid == word_dict.get(bio[1])[0]: \n",
        "        y.append(real_wid)\n",
        "    elif fake_wid == word_dict.get(bio[1])[0]:\n",
        "        y.append(fake_wid) \n",
        "    else:\n",
        "        print('error')\n",
        "       \n",
        "  x = bio_array\n",
        "  y = y  \n",
        "  return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCBUAwvi_USL"
      },
      "outputs": [],
      "source": [
        "word_tensors = make_tensors('/content/NLP-DL-Group2/hw#1/mix.train.tok',vocab,words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl0nTQpjrKmU"
      },
      "outputs": [],
      "source": [
        "def get_input_batch(data, seq_len, idx):\n",
        "    src = data[:, idx:idx+seq_len]                     \n",
        "    return src "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8iFGA8-eQOW",
        "outputId": "ce65cd18-a663-46e0-8997-2e4d206967bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input = torch.tensor(word_tensors[0][100],device = device).reshape(-1,1)\n",
        "def LSTM_Classify(input, model, vocab, word_dict, device, seed=None):\n",
        "  real_wid = word_dict.get('[REAL]')[0]\n",
        "  fake_wid = word_dict.get('[FAKE]')[0]\n",
        "  if seed is not None:\n",
        "      torch.manual_seed(seed)\n",
        "  model.eval() \n",
        "  input = torch.transpose(input, 0, 1) \n",
        "  num_batches = input.shape[-1]  \n",
        "  input = input[:,(num_batches -1) % seq_len :]\n",
        "  num_batches = input.shape[-1]  \n",
        "  batch_size = 1  \n",
        "  hidden = model.init_hidden(batch_size, device)\n",
        "  prediction = None\n",
        "  for idx in range(0, num_batches - 1, seq_len): \n",
        "            hidden = model.detach_hidden(hidden)\n",
        "            src  = get_input_batch(input, seq_len, idx)\n",
        "            src  = src.to(device)  \n",
        "            prediction, hidden = model(src, hidden)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      if(prediction == None): \n",
        "        print(input.size())\n",
        "        return 124\n",
        "      prediction = prediction.reshape(batch_size * seq_len, -1)  \n",
        "      probs = torch.softmax(prediction[-1, :] , dim=-1)   \n",
        "      real_prediction = probs[real_wid]\n",
        "      fake_prediction = probs[fake_wid] \n",
        "      if real_prediction > fake_prediction:\n",
        "        prediction = real_wid\n",
        "      else:\n",
        "        prediction = fake_wid\n",
        "   \n",
        "  return prediction \n",
        "LSTM_Classify(input,model,vocab,words,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dxlH2qhjeV7t"
      },
      "outputs": [],
      "source": [
        "# print(len(word_tensors[1]))\n",
        "y_true=[] \n",
        "y_pred=[]\n",
        "correct = 0\n",
        "# for index in range(500):\n",
        "for index in range(len(word_tensors[1])):\n",
        "  item = torch.tensor(word_tensors[0][index],device = device).reshape(-1,1)\n",
        "  prediction = LSTM_Classify(item,model,vocab,words,device)\n",
        "  actual = word_tensors[1][index] \n",
        "  if(prediction == 637):\n",
        "    y_pred.append(1)\n",
        "  else:\n",
        "    y_pred.append(0)\n",
        "  if(actual == 637):\n",
        "    y_true.append(1)\n",
        "  else:\n",
        "    y_true.append(0)\n",
        "  if prediction == actual:\n",
        "    correct += 1\n",
        "  \n",
        "# print(correct/500)\n",
        "print(correct)\n",
        "print(correct/len(word_tensors[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6pNqp3zw4FOa",
        "outputId": "ccadfd66-2913-429a-d5c5-77af435a7a01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2971,  942],\n",
              "       [2252, 1797]])"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_true, y_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1lNBY2MVcB4NqCeNGhWzL9Ah6uihzwvYG",
      "authorship_tag": "ABX9TyPVlP8ftcGnh9O3O8do6upf",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}