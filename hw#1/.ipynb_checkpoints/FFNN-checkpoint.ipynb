{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cdfc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50dc4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(vocab,corpus):\n",
    "    \n",
    "    text = ''\n",
    "    for i in range(len(corpus)):\n",
    "        wID = corpus[i]\n",
    "        text = text + vocab[wID] + ' '\n",
    "    return(text)\n",
    "\n",
    "def encode(words,text):\n",
    "    corpus = []\n",
    "    tokens = text.split(' ')\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            wID = words[t][0]\n",
    "        except:\n",
    "            wID = words['<unk>'][0]\n",
    "        corpus.append(wID)\n",
    "    return(corpus)\n",
    "\n",
    "def read_encode(file_name,vocab,words,corpus,threshold):\n",
    "    \n",
    "    wID = len(vocab)\n",
    "    \n",
    "    if threshold > -1:\n",
    "        with open(file_name,'rt', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                line = line.replace('\\n','')\n",
    "                # Added lower-casing\n",
    "                line = line.lower()\n",
    "                \n",
    "                # Strips out all charcters other than alphanumeric\n",
    "                line = re.sub('[\\W_]+', ' ', line, flags=re.UNICODE)\n",
    "                \n",
    "                # Strips out numbers\n",
    "                line = re.sub('\\d+', '', line)\n",
    "                \n",
    "                tokens = line.split(' ')\n",
    "                for t in tokens:\n",
    "                    try:\n",
    "                        elem = words[t]\n",
    "                    except:\n",
    "                        elem = [wID,0]\n",
    "                        vocab.append(t)\n",
    "                        wID = wID + 1\n",
    "                    elem[1] = elem[1] + 1\n",
    "                    words[t] = elem\n",
    "\n",
    "        temp = words\n",
    "        words = {}\n",
    "        vocab = []\n",
    "        wID = 0\n",
    "        words['<unk>'] = [wID,100]\n",
    "        vocab.append('<unk>')\n",
    "        for t in temp:\n",
    "            if temp[t][1] >= threshold:\n",
    "                vocab.append(t)\n",
    "                wID = wID + 1\n",
    "                words[t] = [wID,temp[t][1]]\n",
    "            \n",
    "                    \n",
    "    with open(file_name,'rt', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n','')\n",
    "            tokens = line.split(' ')\n",
    "            for t in tokens:\n",
    "                try:\n",
    "                    wID = words[t][0]\n",
    "                except:\n",
    "                    wID = words['<unk>'][0]\n",
    "                corpus.append(wID)\n",
    "                \n",
    "    return [vocab,words,corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1425238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab: 33633 train: 3366260\n",
      "vocab: 33633 test: 441210\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'd_model': 100,\n",
    "        'd_hidden': 100,\n",
    "        'n_layers': 2,\n",
    "        'batch_size': 20,\n",
    "        'seq_len': 30,\n",
    "        'printevery': 5000,\n",
    "        'window': 3,\n",
    "        'epochs': 20,\n",
    "        'lr': 0.0001,\n",
    "        'dropout': 0.35,\n",
    "        'clip': 2.0,\n",
    "        'model': 'FFNN',\n",
    "        'savename': 'lstm',\n",
    "        'loadname': None,\n",
    "        'trainname': 'mix.train.txt',\n",
    "        'validname': 'mix.valid.txt',\n",
    "        'testname': 'mix.test.txt'\n",
    "    }\n",
    "torch.manual_seed(0)\n",
    "\n",
    "[vocab,words,train] = read_encode(params['trainname'],[],{},[],3)\n",
    "print('vocab: %d train: %d' % (len(vocab), len(train)))\n",
    "[vocab,words,test] = read_encode(params['testname'], vocab,words,[],-1)\n",
    "print('vocab: %d test: %d' % (len(vocab),len(test)))\n",
    "params['vocab_size'] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a6bf0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': [0, 100],\n",
       " '': [1, 516387],\n",
       " 'start': [2, 8048],\n",
       " 'bio': [3, 15934],\n",
       " 'hildebrand': [4, 17],\n",
       " 'bothe': [5, 11],\n",
       " 'october': [6, 1610],\n",
       " 'september': [7, 1525],\n",
       " 'was': [8, 50623],\n",
       " 'a': [9, 52817],\n",
       " 'swiss': [10, 276],\n",
       " 'botanist': [11, 1152],\n",
       " 'born': [12, 6232],\n",
       " 'in': [13, 98637],\n",
       " 'strasbourg': [14, 213],\n",
       " 'and': [15, 77821],\n",
       " 'studied': [16, 3552],\n",
       " 'medicine': [17, 1291],\n",
       " 'stuttgart': [18, 180],\n",
       " 'bonn': [19, 186],\n",
       " 'with': [20, 11974],\n",
       " 'dissertation': [21, 343],\n",
       " 'on': [22, 18211],\n",
       " 'plants': [23, 810],\n",
       " 'collected': [24, 414],\n",
       " 'at': [25, 26330],\n",
       " 'the': [26, 146257],\n",
       " 'geofried': [27, 1],\n",
       " 'trier': [28, 28],\n",
       " 'sent': [29, 360],\n",
       " 'by': [30, 9396],\n",
       " 'natural': [31, 1790],\n",
       " 'history': [32, 2917],\n",
       " 'collection': [33, 895],\n",
       " 'of': [34, 118356],\n",
       " 'london': [35, 3215],\n",
       " 'society': [36, 5339],\n",
       " 'to': [37, 37719],\n",
       " 'belgium': [38, 135],\n",
       " 'he': [39, 56398],\n",
       " 'became': [40, 6711],\n",
       " 'plant': [41, 787],\n",
       " 'pathologist': [42, 107],\n",
       " 'started': [43, 598],\n",
       " 'work': [44, 5276],\n",
       " 'as': [45, 17325],\n",
       " 'taxonomist': [46, 38],\n",
       " 'botanical': [47, 969],\n",
       " 'gardens': [48, 262],\n",
       " 'garden': [49, 448],\n",
       " 'gave': [50, 471],\n",
       " 'long': [51, 477],\n",
       " 'lecture': [52, 172],\n",
       " 'lepidoptera': [53, 192],\n",
       " 'switzerland': [54, 278],\n",
       " 'another': [55, 371],\n",
       " 'genus': [56, 512],\n",
       " 'pezizella': [57, 1],\n",
       " 'this': [58, 3394],\n",
       " 'latter': [59, 250],\n",
       " 'contains': [60, 90],\n",
       " 'catalogue': [61, 232],\n",
       " 'approximately': [62, 38],\n",
       " 'numbers': [63, 105],\n",
       " 'which': [64, 5823],\n",
       " 'have': [65, 948],\n",
       " 'not': [66, 1499],\n",
       " 'yet': [67, 51],\n",
       " 'been': [68, 1495],\n",
       " 'calculated': [69, 21],\n",
       " 'also': [70, 6565],\n",
       " 'wrote': [71, 1796],\n",
       " 'many': [72, 1860],\n",
       " 'other': [73, 1811],\n",
       " 'families': [74, 111],\n",
       " 'including': [75, 1529],\n",
       " 'olive': [76, 23],\n",
       " 'flower': [77, 59],\n",
       " 'pisum': [78, 2],\n",
       " 'excelsa': [79, 1],\n",
       " 'russian': [80, 1231],\n",
       " 'goldenrod': [81, 1],\n",
       " 'fruticosa': [82, 1],\n",
       " 'pallidum': [83, 5],\n",
       " 'old': [84, 670],\n",
       " 'growth': [85, 217],\n",
       " 'laurel': [86, 6],\n",
       " 'lagenaria': [87, 1],\n",
       " 'saccharina': [88, 2],\n",
       " 'died': [89, 4327],\n",
       " 'works': [90, 3770],\n",
       " 'theropoda': [91, 1],\n",
       " 'genera': [92, 202],\n",
       " 'canton': [93, 51],\n",
       " 'coimbatore': [94, 5],\n",
       " 'br√ºssel': [95, 1],\n",
       " 'flora': [96, 787],\n",
       " 'lombardy': [97, 10],\n",
       " 'containing': [98, 106],\n",
       " 'some': [99, 1332],\n",
       " 'hundred': [100, 90],\n",
       " 'new': [101, 5416],\n",
       " 'species': [102, 1192],\n",
       " 'caecosphaeria': [103, 1],\n",
       " 'lutrina': [104, 1],\n",
       " 'lymanthella': [105, 1],\n",
       " 'sabionata': [106, 1],\n",
       " 'epipactylia': [107, 1],\n",
       " 'neotropics': [108, 4],\n",
       " 'three': [109, 1307],\n",
       " 'vols': [110, 291],\n",
       " 'nd': [111, 258],\n",
       " 'edition': [112, 721],\n",
       " 'schleswig': [113, 38],\n",
       " 'holstein': [114, 31],\n",
       " 'from': [115, 15734],\n",
       " 'south': [116, 1253],\n",
       " 'africa': [117, 506],\n",
       " 'iconae': [118, 1],\n",
       " 'plantarum': [119, 64],\n",
       " 'modernarum': [120, 1],\n",
       " 'duo': [121, 25],\n",
       " 'end': [122, 8330],\n",
       " 'fake': [123, 3918],\n",
       " 'hermann': [124, 373],\n",
       " 'robert': [125, 1050],\n",
       " 'kaiser': [126, 104],\n",
       " 'january': [127, 1840],\n",
       " 'german': [128, 3000],\n",
       " 'physicist': [129, 1042],\n",
       " 'who': [130, 3850],\n",
       " 'worked': [131, 3077],\n",
       " 'wilhelm': [132, 772],\n",
       " 'institute': [133, 3157],\n",
       " 'university': [134, 15414],\n",
       " 'jena': [135, 262],\n",
       " 'professor': [136, 6101],\n",
       " 'experimental': [137, 515],\n",
       " 'physics': [138, 2882],\n",
       " 'magneto': [139, 5],\n",
       " 'acoustic': [140, 25],\n",
       " 'theory': [141, 1967],\n",
       " 'ionization': [142, 20],\n",
       " 'carried': [143, 168],\n",
       " 'out': [144, 530],\n",
       " 'studies': [145, 2120],\n",
       " 'magnetic': [146, 135],\n",
       " 'fields': [147, 343],\n",
       " 'his': [148, 27320],\n",
       " 'principal': [149, 471],\n",
       " 'research': [150, 4390],\n",
       " 'high': [151, 1075],\n",
       " 'voltage': [152, 51],\n",
       " 'currents': [153, 33],\n",
       " 'pienza': [154, 2],\n",
       " 'ferromagnetics': [155, 1],\n",
       " 'member': [156, 3985],\n",
       " 'academy': [157, 3157],\n",
       " 'sciences': [158, 2993],\n",
       " 'school': [159, 4076],\n",
       " 'now': [160, 1161],\n",
       " 'part': [161, 1303],\n",
       " 'named': [162, 1906],\n",
       " 'honor': [163, 491],\n",
       " 'its': [164, 2083],\n",
       " 'medals': [165, 27],\n",
       " 'publications': [166, 1553],\n",
       " 'zwischen': [167, 30],\n",
       " 'magnetism': [168, 68],\n",
       " 'wissenschaftliche': [169, 30],\n",
       " 'rechtsleben': [170, 2],\n",
       " 'band': [171, 176],\n",
       " 'parameter': [172, 14],\n",
       " 'anwendungen': [173, 20],\n",
       " '√ºber': [174, 651],\n",
       " 'bef√∂rderung': [175, 3],\n",
       " 'des': [176, 2510],\n",
       " 'magneticen': [177, 1],\n",
       " 'vereins': [178, 32],\n",
       " 'untersuchungen': [179, 134],\n",
       " 'die': [180, 1794],\n",
       " 'sonstigen': [181, 1],\n",
       " 'absorption': [182, 57],\n",
       " 'und': [183, 1922],\n",
       " 'electrodynamik': [184, 1],\n",
       " 'mathematische': [185, 57],\n",
       " 'annalen': [186, 52],\n",
       " 'br√ºckempferzung': [187, 1],\n",
       " 'eines': [188, 42],\n",
       " 'elektrotechnische': [189, 3],\n",
       " 'buchstimme': [190, 1],\n",
       " 'das': [191, 428],\n",
       " 'infiniertr√ºstung': [192, 1],\n",
       " 'ammerphysik': [193, 1],\n",
       " 'chemie': [194, 48],\n",
       " 'physik': [195, 184],\n",
       " 'magnetiosepenflorzenwahl': [196, 2],\n",
       " '√∂kologischen': [197, 4],\n",
       " 'krankheiten': [198, 19],\n",
       " 'bei': [199, 117],\n",
       " 'den': [200, 445],\n",
       " 'vogel': [201, 35],\n",
       " 'electrochemical': [202, 17],\n",
       " 'kolemnosepenflorzenwahl': [203, 1],\n",
       " 'ihre': [204, 75],\n",
       " 'antikeln√ºskehrnung': [205, 1],\n",
       " 'einer': [206, 130],\n",
       " 'phenomen': [207, 1],\n",
       " 'wandlekontrolle': [208, 1],\n",
       " 'rods': [209, 12],\n",
       " 'durch': [210, 64],\n",
       " 'einem': [211, 25],\n",
       " 'fachigkeiten': [212, 1],\n",
       " 'sein': [213, 11],\n",
       " 'lebennung': [214, 1],\n",
       " 'infinierts': [215, 1],\n",
       " 'entwurfs': [216, 1],\n",
       " 'an': [217, 11999],\n",
       " 'grieb': [218, 5],\n",
       " 'zusammenschaft': [219, 1],\n",
       " 'naturforschende': [220, 4],\n",
       " 'zum': [221, 111],\n",
       " 'begr√ºndung': [222, 8],\n",
       " 'von': [223, 1615],\n",
       " 'kleine': [224, 19],\n",
       " 'alois': [225, 41],\n",
       " 'obermeyer': [226, 1],\n",
       " 'zur': [227, 532],\n",
       " 'elektrodynamik': [228, 6],\n",
       " 'der': [229, 3527],\n",
       " 'k√∂rper': [230, 10],\n",
       " 'verhandlungen': [231, 30],\n",
       " '√§ltere': [232, 2],\n",
       " 'edited': [233, 464],\n",
       " 'karl': [234, 653],\n",
       " 'rafitsch': [235, 1],\n",
       " 'mainz': [236, 77],\n",
       " 'physikalische': [237, 55],\n",
       " 'gesellschaft': [238, 199],\n",
       " 'wien': [239, 145],\n",
       " 'munich': [240, 589],\n",
       " 'mechanik': [241, 25],\n",
       " 'matter': [242, 144],\n",
       " 'eiffel': [243, 10],\n",
       " 'tower': [244, 28],\n",
       " 'enrico': [245, 46],\n",
       " 'veneziano': [246, 5],\n",
       " 'march': [247, 1729],\n",
       " 'november': [248, 1510],\n",
       " 'italian': [249, 559],\n",
       " 'meteorologist': [250, 115],\n",
       " 'known': [251, 2937],\n",
       " 'for': [252, 17592],\n",
       " 'atmospheric': [253, 125],\n",
       " 'chemical': [254, 478],\n",
       " 'cycles': [255, 18],\n",
       " 'cyclones': [256, 17],\n",
       " 'one': [257, 3339],\n",
       " 'foundational': [258, 23],\n",
       " 'tropical': [259, 141],\n",
       " 'th': [260, 978],\n",
       " 'century': [261, 718],\n",
       " 'biography': [262, 2025],\n",
       " 'crotone': [263, 2],\n",
       " 'di': [264, 386],\n",
       " 'monte': [265, 27],\n",
       " 'cagli': [266, 1],\n",
       " 'north': [267, 938],\n",
       " 'east': [268, 600],\n",
       " 'rome': [269, 463],\n",
       " 'but': [270, 2168],\n",
       " 'raised': [271, 168],\n",
       " 'palermo': [272, 16],\n",
       " 'took': [273, 1286],\n",
       " 'b': [274, 1450],\n",
       " 'sc': [275, 170],\n",
       " 'under': [276, 2123],\n",
       " 'giulio': [277, 15],\n",
       " 'ganti': [278, 1],\n",
       " 'researcher': [279, 235],\n",
       " 'national': [280, 2693],\n",
       " 'meteorological': [281, 166],\n",
       " 'that': [282, 6121],\n",
       " 'time': [283, 2474],\n",
       " 'instituto': [284, 45],\n",
       " 'atmospherici': [285, 1],\n",
       " 'during': [286, 2984],\n",
       " 'world': [287, 2336],\n",
       " 'war': [288, 2313],\n",
       " 'i': [289, 1504],\n",
       " 'received': [290, 2733],\n",
       " 'nobel': [291, 318],\n",
       " 'prize': [292, 1054],\n",
       " 'mid': [293, 128],\n",
       " 's': [294, 15254],\n",
       " 'continued': [295, 865],\n",
       " 'dr': [296, 748],\n",
       " 'giovanni': [297, 134],\n",
       " 'matta': [298, 1],\n",
       " 'between': [299, 1215],\n",
       " 'director': [300, 2542],\n",
       " 'geochemistry': [301, 37],\n",
       " 'spectroscopy': [302, 104],\n",
       " 'geometrina': [303, 1],\n",
       " 'elected': [304, 2066],\n",
       " 'fellow': [305, 2112],\n",
       " 'royal': [306, 3510],\n",
       " 'canada': [307, 555],\n",
       " 'examiner': [308, 52],\n",
       " 'council': [309, 780],\n",
       " 'first': [310, 6020],\n",
       " 'international': [311, 1262],\n",
       " 'scientific': [312, 1740],\n",
       " 'study': [313, 2227],\n",
       " 'climate': [314, 79],\n",
       " 'csicop': [315, 1],\n",
       " 'representative': [316, 126],\n",
       " 'italy': [317, 374],\n",
       " 'serve': [318, 165],\n",
       " 'president': [319, 2463],\n",
       " 'following': [320, 993],\n",
       " 'year': [321, 1901],\n",
       " 'chaired': [322, 90],\n",
       " 'united': [323, 1883],\n",
       " 'nations': [324, 185],\n",
       " 'served': [325, 2833],\n",
       " 'intergovernmental': [326, 10],\n",
       " 'panel': [327, 39],\n",
       " 'change': [328, 132],\n",
       " 'person': [329, 242],\n",
       " 'explore': [330, 35],\n",
       " 'document': [331, 36],\n",
       " 'circulation': [332, 48],\n",
       " 'developed': [333, 766],\n",
       " 'concept': [334, 229],\n",
       " 'wave': [335, 110],\n",
       " 'dispersal': [336, 7],\n",
       " 'cyclone': [337, 3],\n",
       " 'cycle': [338, 82],\n",
       " 'described': [339, 827],\n",
       " 'it': [340, 2350],\n",
       " 'system': [341, 759],\n",
       " 'microvortices': [342, 1],\n",
       " 'period': [343, 606],\n",
       " 'traveled': [344, 184],\n",
       " 'amazon': [345, 29],\n",
       " 'peru': [346, 40],\n",
       " 'colombia': [347, 35],\n",
       " 'medical': [348, 1553],\n",
       " 'ornithological': [349, 114],\n",
       " 'experts': [350, 47],\n",
       " 'brazilian': [351, 70],\n",
       " 'chilean': [352, 24],\n",
       " 'governments': [353, 20],\n",
       " 'european': [354, 380],\n",
       " 'american': [355, 4375],\n",
       " 'jack': [356, 67],\n",
       " 'kopp': [357, 4],\n",
       " 'reported': [358, 107],\n",
       " 'observations': [359, 336],\n",
       " 'these': [360, 752],\n",
       " 'famous': [361, 458],\n",
       " 'paper': [362, 544],\n",
       " 'has': [363, 1009],\n",
       " 'awarded': [364, 1710],\n",
       " 'seven': [365, 255],\n",
       " 'prizes': [366, 42],\n",
       " 'geological': [367, 1150],\n",
       " 'most': [368, 1496],\n",
       " 'recently': [369, 79],\n",
       " 'term': [370, 327],\n",
       " 'margaret': [371, 323],\n",
       " 'hebert': [372, 23],\n",
       " 'thomson': [373, 138],\n",
       " 'composer': [374, 819],\n",
       " 'sixties': [375, 4],\n",
       " 'she': [376, 6526],\n",
       " 'music': [377, 2671],\n",
       " 'educator': [378, 360],\n",
       " 'co': [379, 1022],\n",
       " 'founder': [380, 561],\n",
       " 'thunderclap': [381, 1],\n",
       " 'group': [382, 731],\n",
       " 'author': [383, 1356],\n",
       " 'several': [384, 1589],\n",
       " 'orchestral': [385, 109],\n",
       " 'directed': [386, 170],\n",
       " 'minnesota': [387, 233],\n",
       " 'state': [388, 1665],\n",
       " 'opera': [389, 636],\n",
       " 'thirteen': [390, 34],\n",
       " 'years': [391, 3193],\n",
       " 'before': [392, 1148],\n",
       " 'retiring': [393, 144],\n",
       " 'orchestra': [394, 742],\n",
       " 'married': [395, 2430],\n",
       " 'vocalist': [396, 6],\n",
       " 'bill': [397, 60],\n",
       " 'minneapolis': [398, 29],\n",
       " 'her': [399, 4209],\n",
       " 'father': [400, 1960],\n",
       " 'william': [401, 1847],\n",
       " 'godfrey': [402, 14],\n",
       " 'taught': [403, 1565],\n",
       " 'graduating': [404, 558],\n",
       " 'after': [405, 5054],\n",
       " 'went': [406, 1305],\n",
       " 'harvard': [407, 708],\n",
       " 'graduated': [408, 1365],\n",
       " 'yale': [409, 409],\n",
       " 'left': [410, 859],\n",
       " 'pursue': [411, 91],\n",
       " 'career': [412, 2944],\n",
       " 'education': [413, 1990],\n",
       " 'bachelor': [414, 541],\n",
       " 'degree': [415, 1972],\n",
       " 'unwed': [416, 1],\n",
       " 'motherhood': [417, 5],\n",
       " 'vocalists': [418, 4],\n",
       " 'st': [419, 1765],\n",
       " 'paul': [420, 857],\n",
       " 'symphony': [421, 291],\n",
       " 'vocals': [422, 3],\n",
       " 'david': [423, 604],\n",
       " 'almond': [424, 1],\n",
       " 'lyrics': [425, 22],\n",
       " 'become': [426, 649],\n",
       " 'popular': [427, 389],\n",
       " 'song': [428, 155],\n",
       " 'when': [429, 1790],\n",
       " 'you': [430, 102],\n",
       " 'wear': [431, 10],\n",
       " 'lipstick': [432, 1],\n",
       " 'had': [433, 4572],\n",
       " 'wanted': [434, 70],\n",
       " 'still': [435, 445],\n",
       " 'didn': [436, 5],\n",
       " 'let': [437, 26],\n",
       " 'me': [438, 62],\n",
       " 'sing': [439, 21],\n",
       " 'true': [440, 87],\n",
       " 'musical': [441, 435],\n",
       " 'pride': [442, 15],\n",
       " 'real': [443, 4170],\n",
       " 'unselfish': [444, 1],\n",
       " 'love': [445, 131],\n",
       " 'wince': [446, 1],\n",
       " 'cry': [447, 7],\n",
       " 'affection': [448, 6],\n",
       " 'is': [449, 6221],\n",
       " 'say': [450, 36],\n",
       " 'mother': [451, 589],\n",
       " 've': [452, 7],\n",
       " 'all': [453, 909],\n",
       " 'mary': [454, 647],\n",
       " 'if': [455, 195],\n",
       " 'daughter': [456, 1172],\n",
       " 'somehow': [457, 6],\n",
       " 'heard': [458, 52],\n",
       " 'joy': [459, 29],\n",
       " 'ease': [460, 11],\n",
       " 'longing': [461, 1],\n",
       " 'sacrifice': [462, 8],\n",
       " 'thought': [463, 247],\n",
       " 'no': [464, 899],\n",
       " 'easier': [465, 9],\n",
       " 'or': [466, 1348],\n",
       " 'greater': [467, 76],\n",
       " 'things': [468, 84],\n",
       " 'they': [469, 1704],\n",
       " 'seek': [470, 22],\n",
       " 'maybe': [471, 3],\n",
       " 'd': [472, 3399],\n",
       " 'run': [473, 76],\n",
       " 'down': [474, 142],\n",
       " 'too': [475, 88],\n",
       " 'someday': [476, 2],\n",
       " 'we': [477, 167],\n",
       " 'fly': [478, 32],\n",
       " 'into': [479, 1545],\n",
       " 'arms': [480, 39],\n",
       " 'composed': [481, 277],\n",
       " 'my': [482, 161],\n",
       " 'children': [483, 1269],\n",
       " 'singers': [484, 49],\n",
       " 'cello': [485, 203],\n",
       " 'based': [486, 611],\n",
       " 'tale': [487, 26],\n",
       " 'about': [488, 1118],\n",
       " 'daughterhood': [489, 1],\n",
       " 'shelley': [490, 4],\n",
       " 'honorary': [491, 1035],\n",
       " 'doctorate': [492, 1197],\n",
       " 'southern': [493, 368],\n",
       " 'california': [494, 1164],\n",
       " 'wolfgang': [495, 120],\n",
       " 'count': [496, 86],\n",
       " 'hohenlohe': [497, 11],\n",
       " 'weikersheim': [498, 7],\n",
       " 'june': [499, 1794],\n",
       " 'waldenburg': [500, 6],\n",
       " 'son': [501, 2404],\n",
       " 'louis': [502, 746],\n",
       " 'casimir': [503, 45],\n",
       " 'styled': [504, 9],\n",
       " 'himself': [505, 480],\n",
       " 'neuenstein': [506, 1],\n",
       " 'langenburg': [507, 1],\n",
       " 'k√ºnzelsau': [508, 1],\n",
       " 'kirchberg': [509, 2],\n",
       " 'ingelfingen': [510, 1],\n",
       " 'wife': [511, 1199],\n",
       " 'anna': [512, 238],\n",
       " 'solms': [513, 5],\n",
       " 'lich': [514, 1],\n",
       " 'early': [515, 2516],\n",
       " 'life': [516, 4869],\n",
       " 'two': [517, 2574],\n",
       " 'brothers': [518, 174],\n",
       " 'philip': [519, 207],\n",
       " 'albert': [520, 522],\n",
       " 'nassau': [521, 18],\n",
       " 'army': [522, 642],\n",
       " 'via': [523, 50],\n",
       " 'marriage': [524, 246],\n",
       " 'magdalena': [525, 17],\n",
       " 'dillenburg': [526, 3],\n",
       " 'involved': [527, 501],\n",
       " 'eighty': [528, 24],\n",
       " 'although': [529, 365],\n",
       " 'details': [530, 42],\n",
       " 'involvement': [531, 56],\n",
       " 'are': [532, 1616],\n",
       " 'scarce': [533, 3],\n",
       " 'best': [534, 822],\n",
       " 'reconstruction': [535, 31],\n",
       " 'castle': [536, 82],\n",
       " 'renaissance': [537, 37],\n",
       " 'palace': [538, 57],\n",
       " 'designed': [539, 130],\n",
       " 'dutch': [540, 425],\n",
       " 'architect': [541, 115],\n",
       " 'georg': [542, 366],\n",
       " 'robin': [543, 53],\n",
       " 'located': [544, 90],\n",
       " 'county': [545, 338],\n",
       " 'divided': [546, 50],\n",
       " 'death': [547, 2043],\n",
       " 'issue': [548, 142],\n",
       " 'younger': [549, 226],\n",
       " 'sister': [550, 300],\n",
       " 'silent': [551, 15],\n",
       " 'catherine': [552, 106],\n",
       " 'agnes': [553, 85],\n",
       " 'ernest': [554, 263],\n",
       " 'gleichen': [555, 4],\n",
       " 'tonna': [556, 3],\n",
       " 'spiegelberg': [557, 3],\n",
       " 'pyrmont': [558, 1],\n",
       " 'george': [559, 1172],\n",
       " 'countess': [560, 15],\n",
       " 'walpurga': [561, 1],\n",
       " 'frederick': [562, 363],\n",
       " 'july': [563, 1729],\n",
       " 'juliana': [564, 2],\n",
       " 'ii': [565, 936],\n",
       " 'castell': [566, 3],\n",
       " 'remlingen': [567, 1],\n",
       " 'december': [568, 1740],\n",
       " 'april': [569, 1753],\n",
       " 'henry': [570, 906],\n",
       " 'reuss': [571, 10],\n",
       " 'gera': [572, 5],\n",
       " 'xvi': [573, 26],\n",
       " 'second': [574, 1301],\n",
       " 'dorothea': [575, 40],\n",
       " 'sonnewalde': [576, 6],\n",
       " 'praxedis': [577, 1],\n",
       " 'may': [578, 1827],\n",
       " 'august': [579, 1869],\n",
       " 'marta': [580, 6],\n",
       " 'john': [581, 2507],\n",
       " 'leiningen': [582, 1],\n",
       " 'westerburg': [583, 1],\n",
       " 'maria': [584, 344],\n",
       " 'elisabeth': [585, 85],\n",
       " 'johann': [586, 621],\n",
       " 'reinhard': [587, 32],\n",
       " 'hanau': [588, 10],\n",
       " 'lichtenberg': [589, 19],\n",
       " 'february': [590, 1706],\n",
       " 'bitche': [591, 1],\n",
       " 'v': [592, 450],\n",
       " 'ludowika': [593, 1],\n",
       " 'margaretha': [594, 11],\n",
       " 'zweibr√ºcken': [595, 7],\n",
       " 'bitsch': [596, 1],\n",
       " 'ingweiler': [597, 1],\n",
       " 'buchsweiler': [598, 1],\n",
       " 'joanna': [599, 13],\n",
       " 'crato': [600, 3],\n",
       " 'vii': [601, 68],\n",
       " 'palatine': [602, 17],\n",
       " 'sophia': [603, 54],\n",
       " 'birkenfeld': [604, 2],\n",
       " 'charles': [605, 1192],\n",
       " 'brunswick': [606, 52],\n",
       " 'l√ºneburg': [607, 6],\n",
       " 'ottweiler': [608, 1],\n",
       " 'otto': [609, 384],\n",
       " 'amalia': [610, 7],\n",
       " 'weilburg': [611, 3],\n",
       " 'estrasburgo': [612, 1],\n",
       " 'eldest': [613, 187],\n",
       " 'walburga': [614, 1],\n",
       " 'until': [615, 3047],\n",
       " 'plauen': [616, 1],\n",
       " 'ancestry': [617, 36],\n",
       " 'moshe': [618, 28],\n",
       " 'volkmann': [619, 18],\n",
       " 'hebrew': [620, 337],\n",
       " '◊û◊ê◊ï◊ù': [621, 1],\n",
       " '◊®◊û◊ô◊ù': [622, 1],\n",
       " 'feodosia': [623, 2],\n",
       " 'yiddish': [624, 16],\n",
       " 'israeli': [625, 77],\n",
       " 'historian': [626, 338],\n",
       " 'academic': [627, 741],\n",
       " 'political': [628, 967],\n",
       " 'philosopher': [629, 253],\n",
       " 'literature': [630, 551],\n",
       " 'foundations': [631, 137],\n",
       " 'philosophy': [632, 951],\n",
       " 'published': [633, 4036],\n",
       " 'book': [634, 1493],\n",
       " 'reprinted': [635, 93],\n",
       " 'concepts': [636, 81],\n",
       " 'constitutionalism': [637, 2],\n",
       " 'democratization': [638, 1],\n",
       " 'discourse': [639, 23],\n",
       " 'views': [640, 170],\n",
       " 'championed': [641, 20],\n",
       " 'idea': [642, 204],\n",
       " 'sphere': [643, 26],\n",
       " 'expression': [644, 49],\n",
       " 'promoted': [645, 356],\n",
       " 'people': [646, 452],\n",
       " 'could': [647, 453],\n",
       " 'participate': [648, 26],\n",
       " 'debates': [649, 17],\n",
       " 'create': [650, 97],\n",
       " 'sustain': [651, 2],\n",
       " 'strong': [652, 178],\n",
       " 'stable': [653, 21],\n",
       " 'community': [654, 264],\n",
       " 'develop': [655, 166],\n",
       " 'their': [656, 1716],\n",
       " 'talents': [657, 25],\n",
       " 'capabilities': [658, 11],\n",
       " 'contribution': [659, 330],\n",
       " 'focal': [660, 9],\n",
       " 'point': [661, 245],\n",
       " 'personality': [662, 84],\n",
       " 'precursor': [663, 33],\n",
       " 'jerusalem': [664, 130],\n",
       " 'tanner': [665, 18],\n",
       " 'shensi': [666, 1],\n",
       " 'third': [667, 366],\n",
       " 'child': [668, 476],\n",
       " 'attended': [669, 1008],\n",
       " 'shaar': [670, 1],\n",
       " 'harel': [671, 1],\n",
       " 'military': [672, 544],\n",
       " 'boarding': [673, 26],\n",
       " 'native': [674, 329],\n",
       " 'village': [675, 183],\n",
       " 'off': [676, 111],\n",
       " 'moved': [677, 1639],\n",
       " 'paris': [678, 2132],\n",
       " 'sorbonne': [679, 126],\n",
       " 'de': [680, 5468],\n",
       " 'while': [681, 1216],\n",
       " 'french': [682, 1670],\n",
       " 'politics': [683, 255],\n",
       " 'max': [684, 306],\n",
       " 'weber': [685, 71],\n",
       " 'theorist': [686, 68],\n",
       " 'eminent': [687, 116],\n",
       " 'philosophers': [688, 24],\n",
       " 'such': [689, 860],\n",
       " 'maurice': [690, 147],\n",
       " 'merleau': [691, 5],\n",
       " 'ponty': [692, 5],\n",
       " 'marx': [693, 91],\n",
       " 'spare': [694, 32],\n",
       " 'poetry': [695, 122],\n",
       " 'poems': [696, 116],\n",
       " 'were': [697, 3419],\n",
       " 'pseudonym': [698, 35],\n",
       " 'wharf': [699, 2],\n",
       " 'rat': [700, 20],\n",
       " 'efforts': [701, 129],\n",
       " 'creative': [702, 39],\n",
       " 'critique': [703, 43],\n",
       " 'media': [704, 65],\n",
       " 'project': [705, 371],\n",
       " 'set': [706, 369],\n",
       " 'gained': [707, 251],\n",
       " 'literary': [708, 201],\n",
       " 'pieces': [709, 215],\n",
       " 'moses': [710, 62],\n",
       " 'rama': [711, 10],\n",
       " 'existentialism': [712, 3],\n",
       " 'created': [713, 449],\n",
       " 'volume': [714, 629],\n",
       " 'monumental': [715, 34],\n",
       " 'arabic': [716, 152],\n",
       " 'grammar': [717, 287],\n",
       " 'talmud': [718, 12],\n",
       " 'words': [719, 102],\n",
       " 'thaddeus': [720, 4],\n",
       " 'deacon': [721, 72],\n",
       " 'famed': [722, 19],\n",
       " 'writing': [723, 342],\n",
       " 'complete': [724, 265],\n",
       " 'them': [725, 538],\n",
       " 'oldest': [726, 67],\n",
       " 'remaining': [727, 70],\n",
       " 'major': [728, 907],\n",
       " 'linguistics': [729, 54],\n",
       " 'fluent': [730, 32],\n",
       " 'speaker': [731, 61],\n",
       " 'apologist': [732, 6],\n",
       " 'zionism': [733, 12],\n",
       " 'found': [734, 645],\n",
       " 'solace': [735, 1],\n",
       " 'because': [736, 328],\n",
       " 'felt': [737, 69],\n",
       " 'minimized': [738, 2],\n",
       " 'aspect': [739, 15],\n",
       " 'arab': [740, 34],\n",
       " 'saw': [741, 123],\n",
       " 'deeply': [742, 33],\n",
       " 'detrimental': [743, 2],\n",
       " 'future': [744, 211],\n",
       " 'civil': [745, 450],\n",
       " 'defense': [746, 136],\n",
       " 'aftermath': [747, 24],\n",
       " 'translators': [748, 6],\n",
       " 'associate': [749, 765],\n",
       " 'began': [750, 1362],\n",
       " 'reform': [751, 97],\n",
       " 'civilian': [752, 55],\n",
       " 'among': [753, 876],\n",
       " 'founders': [754, 280],\n",
       " 'institution': [755, 390],\n",
       " 'founded': [756, 1050],\n",
       " 'aim': [757, 37],\n",
       " 'educational': [758, 226],\n",
       " 'fit': [759, 10],\n",
       " 'needs': [760, 26],\n",
       " 'conducted': [761, 402],\n",
       " 'submitted': [762, 39],\n",
       " 'higher': [763, 189],\n",
       " 'passages': [764, 26],\n",
       " 'islam': [765, 68],\n",
       " 'social': [766, 765],\n",
       " 'vision': [767, 68],\n",
       " 'jewish': [768, 508],\n",
       " 'structure': [769, 399],\n",
       " 'economic': [770, 802],\n",
       " 'interrelationships': [771, 1],\n",
       " 'individual': [772, 108],\n",
       " 'ancient': [773, 337],\n",
       " 'modern': [774, 679],\n",
       " 'simon': [775, 154],\n",
       " 'michel': [776, 82],\n",
       " 'treuv': [777, 1],\n",
       " 'c': [778, 2426],\n",
       " 'treuv√©': [779, 1],\n",
       " 'theologian': [780, 388],\n",
       " 'horsche': [781, 1],\n",
       " 'fuchs': [782, 50],\n",
       " 'hamburg': [783, 291],\n",
       " 'berlin': [784, 2044],\n",
       " 'zoologist': [785, 317],\n",
       " 'anatomist': [786, 132],\n",
       " 'entomologist': [787, 519],\n",
       " 'mineralogist': [788, 149],\n",
       " 'researched': [789, 71],\n",
       " 'leaf': [790, 36],\n",
       " 'bohemia': [791, 60],\n",
       " 'made': [792, 2128],\n",
       " 'zygoptera': [793, 1],\n",
       " 'chrysomelena': [794, 1],\n",
       " 'specieset': [795, 1],\n",
       " 'leipzig': [796, 875],\n",
       " 'lettens': [797, 1],\n",
       " 'iii': [798, 194],\n",
       " 'notes': [799, 1205],\n",
       " 'arnt': [800, 2],\n",
       " 'eliassen': [801, 6],\n",
       " 'norwegian': [802, 328],\n",
       " 'pioneer': [803, 393],\n",
       " 'use': [804, 622],\n",
       " 'numerical': [805, 58],\n",
       " 'analysis': [806, 569],\n",
       " 'computers': [807, 61],\n",
       " 'weather': [808, 103],\n",
       " 'forecasting': [809, 27],\n",
       " 'done': [810, 71],\n",
       " 'advanced': [811, 207],\n",
       " 'princeton': [812, 357],\n",
       " 'jersey': [813, 238],\n",
       " 'together': [814, 491],\n",
       " 'neumann': [815, 116],\n",
       " 'areas': [816, 211],\n",
       " 'included': [817, 751],\n",
       " 'free': [818, 306],\n",
       " 'thermally': [819, 1],\n",
       " 'driven': [820, 26],\n",
       " 'circulations': [821, 1],\n",
       " 'frontogenesis': [822, 1],\n",
       " 'shear': [823, 2],\n",
       " 'gravitational': [824, 34],\n",
       " 'propagation': [825, 77],\n",
       " 'stratified': [826, 3],\n",
       " 'carl': [827, 596],\n",
       " 'gustaf': [828, 59],\n",
       " 'rossby': [829, 4],\n",
       " 'medal': [830, 1374],\n",
       " 'important': [831, 905],\n",
       " 'contributions': [832, 1048],\n",
       " 'dynamical': [833, 27],\n",
       " 'meteorology': [834, 181],\n",
       " 'balzan': [835, 4],\n",
       " 'fundamental': [836, 170],\n",
       " 'dynamic': [837, 31],\n",
       " 'influenced': [838, 247],\n",
       " 'stimulated': [839, 13],\n",
       " 'progress': [840, 110],\n",
       " 'science': [841, 2836],\n",
       " 'past': [842, 77],\n",
       " 'fifty': [843, 58],\n",
       " 'personal': [844, 713],\n",
       " 'brother': [845, 757],\n",
       " 'trond': [846, 1],\n",
       " 'anton': [847, 201],\n",
       " 'resided': [848, 40],\n",
       " 'bekkestua': [849, 1],\n",
       " 'friedrich': [850, 701],\n",
       " 'kaufmann': [851, 16],\n",
       " 'ornithologist': [852, 217],\n",
       " 'museum': [853, 1726],\n",
       " 'curator': [854, 443],\n",
       " 'neustadt': [855, 29],\n",
       " 'aus': [856, 229],\n",
       " 't√ºbingen': [857, 201],\n",
       " 'selected': [858, 1125],\n",
       " 'taxa': [859, 124],\n",
       " 'speciosae': [860, 1],\n",
       " 'fr√ºh': [861, 2],\n",
       " 'natur': [862, 45],\n",
       " 'wissenschaft': [863, 46],\n",
       " 'heilige': [864, 14],\n",
       " 'deutschen': [865, 86],\n",
       " 'aukenergie': [866, 1],\n",
       " 'eine': [867, 152],\n",
       " 'tierfauna': [868, 1],\n",
       " 'bd': [869, 75],\n",
       " 'beitr√§ge': [870, 144],\n",
       " 'arten': [871, 46],\n",
       " 'tribunale': [872, 3],\n",
       " 'sch√§vleravon': [873, 2],\n",
       " 'hortus': [874, 27],\n",
       " 'streptodactylidae': [875, 1],\n",
       " 'd√ºsseldorf': [876, 45],\n",
       " 'herpetochromorpha': [877, 1],\n",
       " 'bibliography': [878, 575],\n",
       " 'la': [879, 2109],\n",
       " 'vall√©e': [880, 16],\n",
       " 'bateau': [881, 2],\n",
       " 'leopold': [882, 153],\n",
       " 'm√∂ckner': [883, 1],\n",
       " 'ph': [884, 957],\n",
       " 'thesis': [885, 531],\n",
       " 'jan': [886, 192],\n",
       " 'muka': [887, 1],\n",
       " 'ovsk': [888, 1],\n",
       " 'muka≈ôovsk√Ω': [889, 16],\n",
       " 'czech': [890, 289],\n",
       " 'linguistic': [891, 28],\n",
       " 'aesthetic': [892, 12],\n",
       " 'prague': [893, 464],\n",
       " 'well': [894, 1339],\n",
       " 'association': [895, 1416],\n",
       " 'structuralism': [896, 3],\n",
       " 'circle': [897, 74],\n",
       " 'development': [898, 1121],\n",
       " 'ideas': [899, 208],\n",
       " 'formalism': [900, 13],\n",
       " 'achievements': [901, 154],\n",
       " 'applied': [902, 425],\n",
       " 'geneva': [903, 279],\n",
       " 'linguist': [904, 90],\n",
       " 'semiotician': [905, 1],\n",
       " 'ferdinand': [906, 194],\n",
       " 'saussure': [907, 17],\n",
       " 'artistic': [908, 83],\n",
       " 'systematically': [909, 12],\n",
       " 'applying': [910, 29],\n",
       " 'extending': [911, 20],\n",
       " 'function': [912, 238],\n",
       " 'reception': [913, 23],\n",
       " 'different': [914, 334],\n",
       " 'periods': [915, 49],\n",
       " 'profound': [916, 30],\n",
       " 'influence': [917, 383],\n",
       " 'structuralist': [918, 3],\n",
       " 'comparable': [919, 4],\n",
       " 'roman': [920, 350],\n",
       " 'jakobson': [921, 5],\n",
       " 'aesthetics': [922, 16],\n",
       " 'doctoral': [923, 343],\n",
       " 'pilsen': [924, 6],\n",
       " 'then': [925, 3071],\n",
       " 'along': [926, 322],\n",
       " 'close': [927, 269],\n",
       " 'friend': [928, 350],\n",
       " 'habilitation': [929, 149],\n",
       " 'm√°ch≈Øv': [930, 1],\n",
       " 'm√°j': [931, 1],\n",
       " 'estetick√°': [932, 1],\n",
       " 'examining': [933, 29],\n",
       " 'romantic': [934, 37],\n",
       " 'poet': [935, 198],\n",
       " 'karel': [936, 40],\n",
       " 'hynek': [937, 1],\n",
       " 'm√°cha': [938, 1],\n",
       " 'field': [939, 1396],\n",
       " 'appointed': [940, 2440],\n",
       " 'bratislava': [941, 15],\n",
       " 'slovakia': [942, 21],\n",
       " 'however': [943, 505],\n",
       " 'like': [944, 262],\n",
       " 'universities': [945, 414],\n",
       " 'closed': [946, 66],\n",
       " 'occupying': [947, 7],\n",
       " 'nazis': [948, 49],\n",
       " 'editor': [949, 841],\n",
       " 'favorable': [950, 4],\n",
       " 'towards': [951, 124],\n",
       " 'communism': [952, 27],\n",
       " 'communist': [953, 196],\n",
       " 'coup': [954, 20],\n",
       " '√©tat': [955, 21],\n",
       " 'full': [956, 637],\n",
       " 'reopened': [957, 5],\n",
       " 'same': [958, 983],\n",
       " 'rector': [959, 301],\n",
       " 'post': [960, 740],\n",
       " 'held': [961, 1107],\n",
       " 'due': [962, 326],\n",
       " 'increasing': [963, 34],\n",
       " 'stalinist': [964, 12],\n",
       " 'pressure': [965, 106],\n",
       " 'recanted': [966, 2],\n",
       " 'prewar': [967, 5],\n",
       " 'semiotic': [968, 4],\n",
       " 'czechoslovak': [969, 50],\n",
       " 'remained': [970, 779],\n",
       " 'position': [971, 1217],\n",
       " 'significance': [972, 67],\n",
       " 'limited': [973, 83],\n",
       " 'membership': [974, 72],\n",
       " 'extended': [975, 90],\n",
       " 'beyond': [976, 66],\n",
       " 'realm': [977, 15],\n",
       " 'poetics': [978, 2],\n",
       " 'theories': [979, 160],\n",
       " 'west': [980, 532],\n",
       " 'remains': [981, 123],\n",
       " 'barriers': [982, 6],\n",
       " 'proposed': [983, 204],\n",
       " 'understand': [984, 50],\n",
       " 'complex': [985, 179],\n",
       " 'form': [986, 348],\n",
       " 'distinguished': [987, 387],\n",
       " 'four': [988, 817],\n",
       " 'basic': [989, 167],\n",
       " 'functions': [990, 215],\n",
       " 'language': [991, 442],\n",
       " 'expressive': [992, 12],\n",
       " 'appellative': [993, 1],\n",
       " 'b√ºhler': [994, 4],\n",
       " 'introduced': [995, 318],\n",
       " 'added': [996, 78],\n",
       " 'fourth': [997, 143],\n",
       " 'emphasis': [998, 39],\n",
       " 'reflected': [999, 36],\n",
       " ...}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18346345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed threshold -- all words will be trained\n",
    "[vocab,words,train] = read_encode(params['trainname'],[],{},[],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bed14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns bios in [(bio without puncutation, label), ...]\n",
    "# 0: FAKE\n",
    "# 1: REAL\n",
    "def read_bios(file_name):\n",
    "    with open(file_name,'rt', encoding='utf8') as f:\n",
    "        all_bios = f.readlines()\n",
    "        \n",
    "    split_bios = []\n",
    "    curr_bio = \"\"\n",
    "    curr_index = 0\n",
    "    while curr_index < len(all_bios):\n",
    "        curr_line = all_bios[curr_index].lower()\n",
    "        # Strips out all charcters other than alphanumeric\n",
    "        curr_line = re.sub('[\\W_]+', ' ', curr_line, flags=re.UNICODE)\n",
    "        \n",
    "        # Strips out numbers\n",
    "        curr_line = re.sub('\\d+', '', curr_line)\n",
    "        \n",
    "        curr_line = curr_line.strip()\n",
    "        \n",
    "        if curr_line == \"start bio\":\n",
    "            # Skips their name\n",
    "            curr_index += 1\n",
    "        \n",
    "        elif curr_line == \"end bio\":\n",
    "            curr_index += 2\n",
    "            if \"FAKE\" in all_bios[curr_index]:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "            \n",
    "            split_bios.append((curr_bio, label))\n",
    "            curr_bio = \"\"\n",
    "        \n",
    "        else:\n",
    "            # Check to ensure not empty space\n",
    "            if curr_line:\n",
    "                if curr_bio == \"\":\n",
    "                    curr_bio = curr_line\n",
    "                else:\n",
    "                    curr_bio += \" \" + curr_line\n",
    "        \n",
    "        curr_index += 1\n",
    "        \n",
    "    \n",
    "    return split_bios\n",
    "    \n",
    "split_bios = read_bios(params['trainname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "716f7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windows\n",
    "# split_bios: [(bio without puncutation, label), ...]\n",
    "# Returns sliding windows (multiple per biography):\n",
    "# [\n",
    "#  [\n",
    "#   (['Hildebrand', 'Bothe', 'October'], 'September'),\n",
    "#   (['Bothe', 'October', 'September'], 'was'),\n",
    "#  ],\n",
    "#  [\n",
    "#   ([Hermann', 'Robert', 'Kaiser'], 'September'),\n",
    "#   ...\n",
    "#  ]\n",
    "# ]\n",
    "\n",
    "# Reference: https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "def create_windows(split_bios, window_size):\n",
    "    sliding_windows = []\n",
    "    for bio, _ in split_bios:\n",
    "        bio_without_nums = ''.join([i for i in bio if not i.isdigit()])\n",
    "        tokens = [token for token in bio_without_nums.split(\" \") if token != \"\"]\n",
    "        \n",
    "        ngrams = []\n",
    "        for i in range(len(tokens) - window_size):\n",
    "            ngrams.append((\n",
    "                [tokens[i + j] for j in range(window_size)],\n",
    "                tokens[i + window_size]\n",
    "            ))\n",
    "        \n",
    "        sliding_windows.append(ngrams)\n",
    "    \n",
    "    return sliding_windows\n",
    "\n",
    "windows = create_windows(split_bios, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d7f644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "all_context = []\n",
    "all_labels = []\n",
    "skipped_labels = 0\n",
    "\n",
    "for each_bio in windows:\n",
    "    for context, label in each_bio:\n",
    "        found_in_words = [word in words for word in context]\n",
    "        found_in_words.extend([label in words])\n",
    "        if all(found_in_words):\n",
    "            all_context.append([words[word][0] for word in context])\n",
    "            all_labels.append([words[label][0]])\n",
    "        else:\n",
    "            all_context.append([0] * len(context))\n",
    "            all_labels.append([0])\n",
    "            \n",
    "            skipped_labels += 1\n",
    "\n",
    "# Skipping certain sliding windows because they weren't found in the dictionary\n",
    "# Unk'd?\n",
    "print(skipped_labels)\n",
    "\n",
    "all_context = torch.LongTensor(all_context)\n",
    "all_labels = torch.LongTensor(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c688286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    # d_model = embedding dimensions\n",
    "    def __init__(self, vocab, words,d_model, d_hidden, dropout):\n",
    "        super().__init__() \n",
    "    \n",
    "        self.vocab = vocab\n",
    "        self.words = words\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.d_model = d_model\n",
    "        self.d_hidden = d_hidden\n",
    "        self.dropout = dropout\n",
    "        self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
    "        \n",
    "        # Context size * dimensions\n",
    "        self.linear1 = nn.Linear(3 * d_model, 128)\n",
    "        self.linear2 = nn.Linear(128, self.vocab_size)\n",
    "        \n",
    "\n",
    "    def forward(self, src):\n",
    "        embeds = self.embeds(src).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "                \n",
    "    def init_weights(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e7437ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [156], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(log_probabilities, label)\n\u001b[1;32m     14\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 15\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: Loss \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i, epochs, loss))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## NON BATCHED\n",
    "\n",
    "model = FFNN(vocab, words, d_model=100, d_hidden=100, dropout=0.1)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):\n",
    "    for i in range(len(all_context)):\n",
    "        context = all_context[i]\n",
    "        label = all_labels[i]\n",
    "        log_probabilities = model(context)\n",
    "        loss = loss_function(log_probabilities, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "    print(\"Epoch {}/{}: Loss {:.4f}\".format(i, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d7cf5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "dataset = TensorDataset(all_context, all_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "35abe784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 1000 loss: 7.588064741134644\n",
      "  batch 2000 loss: 7.059284504413605\n",
      "  batch 3000 loss: 7.006073610782623\n",
      "  batch 4000 loss: 6.927615993022918\n",
      "  batch 5000 loss: 6.919543179988861\n",
      "  batch 6000 loss: 6.864118236541748\n",
      "  batch 7000 loss: 6.855780578136444\n",
      "  batch 8000 loss: 6.875775602340698\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [165], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(log_probabilities, label)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# AFTER BATCHING\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "    # d_model = embedding dimensions\n",
    "    def __init__(self, vocab, words,d_model, d_hidden, dropout):\n",
    "        super().__init__() \n",
    "    \n",
    "        self.vocab = vocab\n",
    "        self.words = words\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.d_model = d_model\n",
    "        self.d_hidden = d_hidden\n",
    "        self.dropout = dropout\n",
    "        self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
    "        \n",
    "        # Context size * dimensions\n",
    "        self.linear1 = nn.Linear(3 * d_model, 128)\n",
    "        self.linear2 = nn.Linear(128, self.vocab_size)\n",
    "        \n",
    "\n",
    "    def forward(self, src):\n",
    "        embeds = self.embeds(src).view((BATCH_SIZE, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "                \n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "model = FFNN(vocab, words, d_model=100, d_hidden=100, dropout=0.1)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0\n",
    "    for i, (context, label) in enumerate(dataloader):\n",
    "        log_probabilities = model(context)\n",
    "        # Collapsing labels to correct dimensions\n",
    "        label = label.squeeze()\n",
    "        loss = loss_function(log_probabilities, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()        \n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'batch': i,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, \"fnn.pt\")\n",
    "        \n",
    "    print(\"Epoch {}/{}: Loss {:.4f}\".format(i, epochs, loss))\n",
    "    \n",
    "print(\"Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
