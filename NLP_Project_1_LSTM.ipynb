{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnshulH/NLP-DL-Group2/blob/lstm/NLP_Project_1_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7U7h5_g6HQj",
        "outputId": "4fa73c00-8929-4921-a985-e83a5ed46f2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-DL-Group2'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/20)\u001b[K\rremote: Counting objects:  10% (2/20)\u001b[K\rremote: Counting objects:  15% (3/20)\u001b[K\rremote: Counting objects:  20% (4/20)\u001b[K\rremote: Counting objects:  25% (5/20)\u001b[K\rremote: Counting objects:  30% (6/20)\u001b[K\rremote: Counting objects:  35% (7/20)\u001b[K\rremote: Counting objects:  40% (8/20)\u001b[K\rremote: Counting objects:  45% (9/20)\u001b[K\rremote: Counting objects:  50% (10/20)\u001b[K\rremote: Counting objects:  55% (11/20)\u001b[K\rremote: Counting objects:  60% (12/20)\u001b[K\rremote: Counting objects:  65% (13/20)\u001b[K\rremote: Counting objects:  70% (14/20)\u001b[K\rremote: Counting objects:  75% (15/20)\u001b[K\rremote: Counting objects:  80% (16/20)\u001b[K\rremote: Counting objects:  85% (17/20)\u001b[K\rremote: Counting objects:  90% (18/20)\u001b[K\rremote: Counting objects:  95% (19/20)\u001b[K\rremote: Counting objects: 100% (20/20)\u001b[K\rremote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 66 (delta 6), reused 6 (delta 1), pack-reused 46\u001b[K\n",
            "Unpacking objects: 100% (66/66), 30.21 MiB | 2.25 MiB/s, done.\n",
            "Updating files: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r /content/NLP-DL-Group2/\n",
        "!cd /content && git clone https://github.com/AnshulH/NLP-DL-Group2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(vocab,corpus):\n",
        "    \n",
        "    text = ''\n",
        "    for i in range(len(corpus)):\n",
        "        wID = corpus[i]\n",
        "        text = text + vocab[wID] + ' '\n",
        "    return(text)\n",
        "\n",
        "def encode(words,text):\n",
        "    corpus = []\n",
        "    tokens = text.split(' ')\n",
        "    for t in tokens:\n",
        "        try:\n",
        "            wID = words[t][0]\n",
        "        except:\n",
        "            wID = words['<unk>'][0]\n",
        "        corpus.append(wID)\n",
        "    return(corpus)\n",
        "\n",
        "def read_encode(file_name,vocab,words,corpus,threshold):\n",
        "    \n",
        "    wID = len(vocab)\n",
        "    \n",
        "    if threshold > -1:\n",
        "        with open(file_name,'rt') as f:\n",
        "            for line in f:\n",
        "                line = line.replace('\\n','')\n",
        "                tokens = line.split(' ')\n",
        "                for t in tokens:\n",
        "                    try:\n",
        "                        elem = words[t]\n",
        "                    except:\n",
        "                        elem = [wID,0]\n",
        "                        vocab.append(t)\n",
        "                        wID = wID + 1\n",
        "                    elem[1] = elem[1] + 1\n",
        "                    words[t] = elem\n",
        "\n",
        "        temp = words\n",
        "        words = {}\n",
        "        vocab = []\n",
        "        wID = 0\n",
        "        words['<unk>'] = [wID,100]\n",
        "        wID = 1\n",
        "        words['<pad>'] = [wID,100]\n",
        "        vocab.append('<unk>')\n",
        "        vocab.append('<pad>')\n",
        "        for t in temp:\n",
        "            if temp[t][1] >= threshold:\n",
        "                vocab.append(t)\n",
        "                wID = wID + 1\n",
        "                words[t] = [wID,temp[t][1]]\n",
        "            \n",
        "                    \n",
        "    with open(file_name,'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.replace('\\n','')\n",
        "            tokens = line.split(' ')\n",
        "            for t in tokens:\n",
        "                try:\n",
        "                    wID = words[t][0]\n",
        "                except:\n",
        "                    wID = words['<unk>'][0]\n",
        "                corpus.append(wID)\n",
        "                \n",
        "    return [vocab,words,corpus]\n",
        "\n",
        "def make_tensors(file_name,sequence_length):\n",
        "  '''\n",
        "  creates a list of tuples containing a list with the tokenized bio and a fake/real label\n",
        "\n",
        "  inputs: \n",
        "    file_name = a complete file path to a mixed dataset containing text and labels\n",
        "    sequence_length = the length of the desired input array\n",
        "  outputs:\n",
        "    x = a tensor containing wIDs of the desired sequence length for each bio\n",
        "    y = a tensor containing the corresponding label for each input\n",
        "  '''\n",
        "  \n",
        "  stop = set(stopwords.words('english') + list(string.punctuation))\n",
        "\n",
        "\n",
        "  with open(file_name) as input:\n",
        "    all_text = input.readlines()\n",
        "\n",
        "# if anybody wants to do some work on the tokenization section, \n",
        "# you should work with the split_bios array, since it contains actual words\n",
        "\n",
        "# split_bios = [([bio1, tokens1],[REAL]),([bio2, tokens2],[FAKE])]\n",
        "  split_bios = []\n",
        "  line_text = []\n",
        "\n",
        "  # seq_status = 0 marks the start of the bio\n",
        "  # seq_status = 1 is the main text of the bio\n",
        "  # seq_status = 2 is the end of the bio\n",
        "  for line in all_text[:200]:\n",
        "    line = line.strip()\n",
        "    if \"<start_bio>\" in line:\n",
        "      seq_status = 0\n",
        "      continue\n",
        "    if \"<end_bio>\" in line:\n",
        "      seq_status = 2\n",
        "      continue\n",
        "    if seq_status == 0:\n",
        "      bio_person = line.strip(\" = \").lower().split()\n",
        "      stop.update(bio_person) # could remove important words if name is meaningful\n",
        "      seq_status = 1\n",
        "    if seq_status == 1:\n",
        "      line = re.sub(\"[\\d-]\", '',line)\n",
        "      line = [token for token in word_tokenize(line.lower()) if token not in stop]\n",
        "      if len(line) > 0:\n",
        "        line_text.extend(line)\n",
        "    if seq_status == 2:\n",
        "      stop -= set(bio_person)\n",
        "      if line == '[FAKE]': #updated code so now fake / real is binary\n",
        "        line = 0\n",
        "      elif line == '[REAL]':\n",
        "        line = 1\n",
        "      else:\n",
        "        continue\n",
        "      split_bios.append((line_text,line))\n",
        "      line_text = []\n",
        "\n",
        "  encodings = read_encode(file_name,[],{},[],3)\n",
        "  word_dict = encodings[1]\n",
        "  vocab_length = max(encodings[2])\n",
        "\n",
        "  bio_array = []\n",
        "  seq_len = sequence_length\n",
        "  y = []\n",
        "\n",
        "  for bio in split_bios:\n",
        "    wid = []\n",
        "    for token in bio[0]:\n",
        "      word_info = word_dict.get(token)\n",
        "      if word_info is None:\n",
        "        wid.append(0)\n",
        "      else:\n",
        "        wid.append(word_info[0])\n",
        "    if len(wid) > seq_len:\n",
        "      wid = wid[:seq_len]\n",
        "    elif len(wid) < seq_len:\n",
        "      pad_size = seq_len - len(wid)\n",
        "      wid.extend(np.ones(pad_size,dtype=int))\n",
        "    bio_array.append(np.array(wid))\n",
        "    y.append(bio[1])\n",
        "\n",
        "  x = torch.tensor(bio_array)\n",
        "  y = torch.tensor(y)\n",
        "\n",
        "  return (x,y)"
      ],
      "metadata": {
        "id": "S92xGxZAejT_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_tensors('/content/NLP-DL-Group2/hw#1/mix.train.txt',512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPSwYc8mEJ0X",
        "outputId": "3f66c1eb-d177-4a73-bb49-b5d7779b784c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[    0,    11,     0,  ...,     1,     1,     1],\n",
              "         [    0,    11,     0,  ...,     1,     1,     1],\n",
              "         [11880,    11,     0,  ...,     1,     1,     1],\n",
              "         ...,\n",
              "         [    0,     0,     0,  ...,     1,     1,     1],\n",
              "         [    0,  6674,     0,  ...,     1,     1,     1],\n",
              "         [    0,     0,     0,  ...,     1,     1,     1]]),\n",
              " tensor([0, 0, 0, 0, 1, 0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words # added for detecting English words\n",
        "import string\n",
        "import nltk\n",
        "import calendar\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3BjxK9QyXLA",
        "outputId": "40f892a1-398a-4cf2-ee0f-c24cb1791118"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop = set(stopwords.words('english') + list(string.punctuation))"
      ],
      "metadata": {
        "id": "LYnopIlVDnnc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of tuples containing a list with the tokenized bio and a fake/real label\n",
        "# split_bios = [([bio1, tokens1],[REAL]),([bio2, tokens2],[FAKE])]\n",
        "\n",
        "original_file = '/content/NLP-DL-Group2/hw#1/mix.train.txt'\n",
        "\n",
        "with open(original_file) as input:\n",
        "  all_text = input.readlines()\n",
        "\n",
        "split_bios = []\n",
        "line_text = []\n",
        "\n",
        "# seq_status = 0 marks the start of the bio\n",
        "# seq_status = 1 is the main text of the bio\n",
        "# seq_status = 2 is the end of the bio\n",
        "for line in all_text:\n",
        "  line = line.strip()\n",
        "  if \"<start_bio>\" in line:\n",
        "    seq_status = 0\n",
        "    continue\n",
        "  if \"<end_bio>\" in line:\n",
        "    seq_status = 2\n",
        "    continue\n",
        "  if seq_status == 0:\n",
        "    bio_person = line.strip(\" = \").lower().split()\n",
        "    stop.update(bio_person) # could remove important words if name is meaningful\n",
        "    seq_status = 1\n",
        "    continue\n",
        "  if seq_status == 1:\n",
        "    line = re.sub(\"[\\d-]\", '',line)\n",
        "    line = [token for token in word_tokenize(line.lower()) if token not in stop]\n",
        "    if len(line) > 0:\n",
        "      line_text.extend(line)\n",
        "  if seq_status == 2 and '[' in line:\n",
        "    stop -= set(bio_person)\n",
        "    if line == '[FAKE]': #updated code so now fake / real is binary\n",
        "      line = 0\n",
        "    else:\n",
        "      line = 1\n",
        "    split_bios.append((line_text,line))\n",
        "    line_text = []\n",
        "\n",
        "# print(split_bios[:2])"
      ],
      "metadata": {
        "id": "_oZAoBCxE8Ht"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = read_encode('/content/NLP-DL-Group2/hw#1/mix.train.tok',[],{},[],3)\n",
        "word_dict = encodings[1]\n",
        "vocab_length = max(encodings[2])\n",
        "\n",
        "bio_array = []\n",
        "seq_len = 512\n",
        "y = []\n",
        "for bio in split_bios:\n",
        "  wid = []\n",
        "  for token in bio[0]:\n",
        "    word_info = word_dict.get(token)\n",
        "    if word_info is None:\n",
        "      wid.append(0)\n",
        "    else:\n",
        "      wid.append(word_info[0])\n",
        "  if len(wid) > seq_len:\n",
        "    wid = wid[:seq_len]\n",
        "  elif len(wid) < seq_len:\n",
        "    pad_size = seq_len - len(wid)\n",
        "    wid.extend(np.ones(pad_size,dtype=int))\n",
        "  bio_array.append(np.array(wid))\n",
        "  y.append(bio[1])\n",
        "\n",
        "list_len = [len(i) for i in bio_array]\n",
        "# print(bio_array[:5])\n",
        "# print(max(list_len))\n",
        "dummy = torch.tensor(bio_array)\n",
        "y = torch.tensor(y)\n",
        "# print(dummy)\n",
        "# print(y)"
      ],
      "metadata": {
        "id": "3apfnestaJt9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ones(4,dtype=int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiAJRgfUl50Q",
        "outputId": "539e5c0e-5994-4a43-cbdb-2dedec8461c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self,vocab,words,d_model,d_hidden,n_layers,dropout_rate):\n",
        "        super().__init__()  \n",
        "        self.vocab = vocab\n",
        "        self.words = words\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.n_layers = n_layers\n",
        "        self.d_hidden = d_hidden\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(self.vocab_size,d_model)\n",
        "        #self.lstm = nn.LSTM(input_size=300,hidden_size=d_hidden,num_layers=1,batch_first=True,bidirectional=True)\n",
        "        self.drop = dropout_rate\n",
        "        self.fc = nn.Linear(d_hidden, 1) \n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=d_model,\n",
        "            hidden_size=d_hidden,\n",
        "            num_layers=n_layers,\n",
        "            dropout=dropout_rate\n",
        "        ) \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lin = nn.Linear(512, 1) \n",
        "        \n",
        "    def forward(self,x,prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        print(embed.size())\n",
        "        print(\"k\")\n",
        "        print(prev_state[0].size())\n",
        "        print(prev_state[1].size())\n",
        "        batch_size = x.size(0)\n",
        "        print(batch_size)\n",
        "        output, state = self.lstm(embed, self.detach_hidden(prev_state))\n",
        "        print(\"dha\")\n",
        "        print(output.size()) \n",
        "        print(state[0].size())\n",
        "        print(state[1].size()) \n",
        "        logits = self.fc(output)\n",
        "        print(logits.size())\n",
        "        out = self.relu(logits)\n",
        "        print(out.size())\n",
        "        out = out.view(batch_size, -1)\n",
        "        print(out.size()) \n",
        "        out = self.lin(out)\n",
        "        out = self.sigmoid(out)\n",
        "        print(out.size())\n",
        "        return out, state \n",
        "        # return [preds,h]\n",
        "    \n",
        "    def init_weights(self,sequence_length): \n",
        "        return (torch.zeros(self.n_layers, 512, self.d_hidden),\n",
        "                torch.zeros(self.n_layers, 512, self.d_hidden))\n",
        "    \n",
        "    def detach_hidden(self, hidden):\n",
        "        h, c = hidden\n",
        "        h = h.detach()\n",
        "        c = c.detach()\n",
        "        return (h,c)\n",
        "       \n",
        "\n",
        "        \n",
        "    "
      ],
      "metadata": {
        "id": "xk0bxuwX0LHW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self, vocab, words,d_model, d_hidden, dropout):\n",
        "        super().__init__() \n",
        "    \n",
        "        self.vocab = vocab\n",
        "        self.words = words\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.d_model = d_model\n",
        "        self.d_hidden = d_hidden\n",
        "        self.dropout = dropout\n",
        "        self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
        "#          {perform other initializations needed for the FFNN}\n",
        "\n",
        "    def forward(self, src):\n",
        "        embeds = self.dropout(self.embeds(src))\n",
        "#          {add code to implement the FFNN}\n",
        "        pass\n",
        "        # return x\n",
        "                \n",
        "    def init_weights(self):\n",
        "      pass\n",
        "#          {perform initializations}\n",
        "             \n",
        "# class LSTM(nn.Module):\n",
        "#     def __init__(self,vocab,words,d_model,d_hidden,n_layers,dropout_rate):\n",
        "#         super().__init__()\n",
        "        \n",
        "#         self.vocab = vocab\n",
        "#         self.words = words\n",
        "#         self.vocab_size = len(self.vocab)\n",
        "#         self.n_layers = n_layers\n",
        "#         self.d_hidden = d_hidden\n",
        "#         self.d_model = d_model\n",
        "#         self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
        "# #          {perform other initializations needed for the LSTM}\n",
        "#         self.lstm = nn.LSTM(d_model, d_hidden, n_layers, dropout=dropout_rate, batch_first=True)\n",
        "#         self.dropout = nn.Dropout(dropout_rate)\n",
        "#         self.fc = nn.Linear(d_hidden, 1)\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "#     def forward(self,src,h):\n",
        "#         embeds = self.dropout(self.embeds(src))\n",
        "#         batch_size = src.size(0)\n",
        "#         src = src.long()\n",
        "#         lstm_out, h = self.lstm(embeds, h)\n",
        "#         lstm_out = lstm_out.contiguous().view(-1, self.d_hidden)\n",
        "        \n",
        "#         out = self.dropout(lstm_out)\n",
        "#         out = self.fc(out)\n",
        "#         out = self.sigmoid(out)\n",
        "        \n",
        "#         out = out.view(batch_size, -1)\n",
        "#         out = out[:,-1]\n",
        "#         return out, h\n",
        "    \n",
        "#     def init_weights(self, batch_size):\n",
        "#         weight = next(self.parameters()).data\n",
        "#         hidden = (weight.new(self.n_layers, batch_size, self.d_hidden).zero_().to(device),\n",
        "#                       weight.new(self.n_layers, batch_size, self.d_hidden).zero_().to(device))\n",
        "#         return hidden\n",
        "        \n",
        "    \n",
        "#     def detach_hidden(self, hidden):\n",
        "#       pass\n",
        "# #          {needed for training...}\n",
        "#         # return [hidden, cell]  \n",
        " \n",
        "def main():\n",
        "    \n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-d_model', type=int, default=100)\n",
        "    parser.add_argument('-d_hidden', type=int, default=100)\n",
        "    parser.add_argument('-n_layers', type=int, default=2)\n",
        "    parser.add_argument('-batch_size', type=int, default=20)\n",
        "    parser.add_argument('-seq_len', type=int, default=30)\n",
        "    parser.add_argument('-printevery', type=int, default=5000)\n",
        "    parser.add_argument('-window', type=int, default=3)\n",
        "    parser.add_argument('-epochs', type=int, default=20)\n",
        "    parser.add_argument('-lr', type=float, default=0.0001)\n",
        "    parser.add_argument('-dropout', type=int, default=0.35)\n",
        "    parser.add_argument('-clip', type=int, default=2.0)\n",
        "    parser.add_argument('-model', type=str,default='LSTM')\n",
        "    parser.add_argument('-savename', type=str,default='lstm')\n",
        "    parser.add_argument('-loadname', type=str)\n",
        "    parser.add_argument('-trainname', type=str,default='wiki.train.txt')\n",
        "    parser.add_argument('-validname', type=str,default='wiki.valid.txt')\n",
        "    parser.add_argument('-testname', type=str,default='wiki.test.txt')\n",
        "\n",
        "    params = {\n",
        "        'd_model': 1,\n",
        "        'd_hidden': 1,\n",
        "        'n_layers': 1,\n",
        "        'batch_size': 100,\n",
        "        'seq_len': 512,\n",
        "        'printevery': 5000,\n",
        "        'window': 3,\n",
        "        'epochs': 20,\n",
        "        'lr': 0.0001,\n",
        "        'dropout': 0.35,\n",
        "        'clip': 2.0,\n",
        "        'model': 'LSTM',\n",
        "        'savename': 'lstm',\n",
        "        'loadname': None,\n",
        "        'trainname': '/content/NLP-DL-Group2/hw#1/mix.train.tok',\n",
        "        'validname': '/content/NLP-DL-Group2/hw#1/mix.train.tok',\n",
        "        'testname': '/content/NLP-DL-Group2/hw#1/mix.train.tok'\n",
        "    }\n",
        "    parser.add_argument(\"-f\", required=False)\n",
        "    \n",
        "    # params = parser.parse_args()    \n",
        "    # torch.manual_seed(0)\n",
        "    \n",
        "    [vocab,words,train] = read_encode(params['trainname'],[],{},[],3)\n",
        "    print('vocab: %d train: %d' % (len(vocab),len(train)))\n",
        "    [vocab,words,test] = read_encode(params['testname'],vocab,words,[],-1)\n",
        "    print('vocab: %d test: %d' % (len(vocab),len(test)))\n",
        "    params['vocab_size'] = len(vocab)\n",
        "\n",
        "    train_loader = read_encode(params['trainname'],[],{},[],3)\n",
        "    \n",
        "    if params['model'] == 'FFNN':\n",
        "      pass\n",
        "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
        "        \n",
        "    if params['model'] == 'LSTM':\n",
        "      model = LSTM(vocab,words,params['d_model'],params['d_hidden'],params['n_layers'],params['dropout']) \n",
        "      model.to(device)\n",
        "\n",
        "      # lr=0.005\n",
        "      # criterion = nn.BCELoss()\n",
        "      # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "      # epochs = 2\n",
        "      # counter = 0\n",
        "      # print_every = 1000\n",
        "      # clip = 5\n",
        "      # valid_loss_min = np.Inf\n",
        "\n",
        "      # model.train()\n",
        "      # print(\"dha\")\n",
        "      # print(list(train_loader[1].items())[0:15])\n",
        "\n",
        "      # for i in range(epochs):\n",
        "      #   h = model.init_weights(params['batch_size'])\n",
        "        \n",
        "      #   for vocab, labels in oops:\n",
        "      #       counter += 1\n",
        "      #       h = tuple([e.data for e in h])\n",
        "      #       vocab, labels = vocab.to(device), labels.to(device)\n",
        "      #       model.zero_grad()\n",
        "      #       output, h = model(vocab, h)\n",
        "      #       loss = criterion(output.squeeze(), labels.float())\n",
        "      #       loss.backward()\n",
        "      #       nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      #       optimizer.step()\n",
        "            \n",
        "      #       if counter%print_every == 0:\n",
        "      #           val_h = model.init_hidden(read_encode(params['validname'],[],{},[],3))\n",
        "      #           val_losses = []\n",
        "      #           model.eval()\n",
        "      #           for inp, lab in params['validname']:\n",
        "      #               val_h = tuple([each.data for each in val_h])\n",
        "      #               inp, lab = inp.to(device), lab.to(device)\n",
        "      #               out, val_h = model(inp, val_h)\n",
        "      #               val_loss = criterion(out.squeeze(), lab.float())\n",
        "      #               val_losses.append(val_loss.item())\n",
        "                    \n",
        "      #           model.train()\n",
        "      #           print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "      #                 \"Step: {}...\".format(counter),\n",
        "      #                 \"Loss: {:.6f}...\".format(loss.item()),\n",
        "      #                 \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
        "      #           if np.mean(val_losses) <= valid_loss_min:\n",
        "      #               torch.save(model.state_dict(), './state_dict.pt')\n",
        "      #               print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
        "      #               valid_loss_min = np.mean(val_losses) \n",
        "      criterion = nn.BCEWithLogitsLoss()\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.5) \n",
        "\n",
        "      for epoch in range(20):  \n",
        "              state_h, state_c = model.init_weights(512)\n",
        "              print(state_h.size())\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              y_pred, (state_h, state_c) = model(dummy[:500], (state_h, state_c))\n",
        "              print(y[:2].size())\n",
        "              print(\"j\")\n",
        "              print(y_pred.view(-1).size())\n",
        "              print(y_pred.type())\n",
        "\n",
        "              w = y.type(torch.FloatTensor)\n",
        "              print(w[:2].type()) \n",
        "              loss = criterion(y_pred.view(-1), w[:500])\n",
        "\n",
        "              state_h = state_h.detach()\n",
        "              state_c = state_c.detach()\n",
        "\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              print({ 'epoch': epoch, 'batch': params['batch_size'], 'loss': loss.item() })\n",
        "\n",
        "\n",
        "    if params['model'] == 'FFNN_CLASSIFY':\n",
        "      pass\n",
        "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n",
        "\n",
        "    if params['model'] == 'LSTM_CLASSIFY':\n",
        "      pass\n",
        "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n",
        "        \n",
        "    print(params)\n",
        "    \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwOAM-Ht6WMu",
        "outputId": "388c931d-b13b-49f3-a99e-29b5e4bd9eed"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab: 35151 train: 3012820\n",
            "vocab: 35151 test: 3012820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 0, 'batch': 100, 'loss': 0.7222668528556824}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 1, 'batch': 100, 'loss': 0.709483802318573}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 2, 'batch': 100, 'loss': 0.7013074159622192}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 3, 'batch': 100, 'loss': 0.6969351172447205}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 4, 'batch': 100, 'loss': 0.694853663444519}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 5, 'batch': 100, 'loss': 0.6939092874526978}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 6, 'batch': 100, 'loss': 0.6934821009635925}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 7, 'batch': 100, 'loss': 0.6932854652404785}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 8, 'batch': 100, 'loss': 0.6931931376457214}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 9, 'batch': 100, 'loss': 0.693149209022522}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 10, 'batch': 100, 'loss': 0.6931287050247192}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 11, 'batch': 100, 'loss': 0.6931195855140686}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 12, 'batch': 100, 'loss': 0.6931158304214478}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 13, 'batch': 100, 'loss': 0.6931151151657104}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 14, 'batch': 100, 'loss': 0.6931158304214478}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 15, 'batch': 100, 'loss': 0.6931171417236328}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 16, 'batch': 100, 'loss': 0.6931183934211731}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 17, 'batch': 100, 'loss': 0.6931200623512268}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 18, 'batch': 100, 'loss': 0.6931215524673462}\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "k\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "500\n",
            "dha\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([1, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512, 1])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500, 1])\n",
            "torch.Size([2])\n",
            "j\n",
            "torch.Size([500])\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "{'epoch': 19, 'batch': 100, 'loss': 0.693122923374176}\n",
            "{'d_model': 1, 'd_hidden': 1, 'n_layers': 1, 'batch_size': 100, 'seq_len': 512, 'printevery': 5000, 'window': 3, 'epochs': 20, 'lr': 0.0001, 'dropout': 0.35, 'clip': 2.0, 'model': 'LSTM', 'savename': 'lstm', 'loadname': None, 'trainname': '/content/NLP-DL-Group2/hw#1/mix.train.tok', 'validname': '/content/NLP-DL-Group2/hw#1/mix.train.tok', 'testname': '/content/NLP-DL-Group2/hw#1/mix.train.tok', 'vocab_size': 35151}\n"
          ]
        }
      ]
    }
  ]
}