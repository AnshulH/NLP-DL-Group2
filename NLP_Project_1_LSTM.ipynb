{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnshulH/NLP-DL-Group2/blob/lstm/NLP_Project_1_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7U7h5_g6HQj",
        "outputId": "e8b22470-01c8-4d61-bf72-0f16721a3814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/NLP-DL-Group2/': No such file or directory\n",
            "Cloning into 'NLP-DL-Group2'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 111 (delta 29), reused 18 (delta 5), pack-reused 46\u001b[K\n",
            "Receiving objects: 100% (111/111), 30.88 MiB | 16.59 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Updating files: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r /content/NLP-DL-Group2/\n",
        "!cd /content && git clone https://github.com/AnshulH/NLP-DL-Group2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words # added for detecting English words\n",
        "import string\n",
        "import nltk\n",
        "import calendar\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3BjxK9QyXLA",
        "outputId": "c753ae0b-3fb9-4231-ed0a-ea1237eb9bc8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(vocab,corpus):\n",
        "    \n",
        "    text = ''\n",
        "    for i in range(len(corpus)):\n",
        "        wID = corpus[i]\n",
        "        text = text + vocab[wID] + ' '\n",
        "    return(text)\n",
        "\n",
        "def encode(words,text):\n",
        "    corpus = []\n",
        "    tokens = text.split(' ')\n",
        "    for t in tokens:\n",
        "        try:\n",
        "            wID = words[t][0]\n",
        "        except:\n",
        "            wID = words['<unk>'][0]\n",
        "        corpus.append(wID)\n",
        "    return(corpus)\n",
        "\n",
        "def read_encode(file_name,vocab,words,corpus,threshold):\n",
        "    \n",
        "    wID = len(vocab)\n",
        "    \n",
        "    if threshold > -1:\n",
        "        with open(file_name,'rt') as f:\n",
        "            for line in f:\n",
        "                line = line.replace('\\n','')\n",
        "                tokens = line.split(' ')\n",
        "                for t in tokens:\n",
        "                    try:\n",
        "                        elem = words[t]\n",
        "                    except:\n",
        "                        elem = [wID,0]\n",
        "                        vocab.append(t)\n",
        "                        wID = wID + 1\n",
        "                    elem[1] = elem[1] + 1\n",
        "                    words[t] = elem\n",
        "\n",
        "        temp = words\n",
        "        words = {}\n",
        "        vocab = []\n",
        "        wID = 0\n",
        "        words['<unk>'] = [wID,100]\n",
        "        wID = 1\n",
        "        words['< start_bio >'] = [wID,100]\n",
        "        wID = 2\n",
        "        words['< end_bio >'] = [wID,100]\n",
        "        vocab.append('<unk>')\n",
        "        vocab.append('< start_bio >')\n",
        "        vocab.append('< end_bio >')\n",
        "        for t in temp:\n",
        "            if temp[t][1] >= threshold:\n",
        "                vocab.append(t)\n",
        "                wID = wID + 1\n",
        "                words[t] = [wID,temp[t][1]]\n",
        "            \n",
        "                    \n",
        "    with open(file_name,'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.replace('\\n','')\n",
        "            tokens = line.split(' ')\n",
        "            for t in tokens:\n",
        "                try:\n",
        "                    wID = words[t][0]\n",
        "                except:\n",
        "                    wID = words['<unk>'][0]\n",
        "                corpus.append(wID)\n",
        "                \n",
        "    return [vocab,words,corpus]\n",
        "\n",
        "def read_alltext(file_name,batch_size):\n",
        "  '''\n",
        "  tokenizes data, removes digits, converts to wIDs, and provides a tensor of batched inputs\n",
        "\n",
        "  inputs: \n",
        "    file_name = a complete file path to a mixed dataset containing text and labels\n",
        "    sequence_length = the length of the desired input array\n",
        "  outputs:\n",
        "    x = a tensor containing wIDs of the input\n",
        "  '''\n",
        "  encodings = read_encode(file_name,[],{},[],3)\n",
        "  word_dict = encodings[1]\n",
        "  wid = []\n",
        "  real_wid = word_dict.get('[REAL]')[0]\n",
        "  fake_wid = word_dict.get('[FAKE]')[0]\n",
        "\n",
        "  with open(file_name) as input:\n",
        "    all_text = input.readlines()\n",
        "\n",
        "  for line in all_text:\n",
        "    line = line.strip()\n",
        "    line = re.sub(\"[\\d-]\", \"\",line)\n",
        "    if \"< start_bio >\" in line:\n",
        "      try:\n",
        "        wid.append(1)\n",
        "      except:\n",
        "        continue\n",
        "    elif \"< end_bio >\" in line:\n",
        "        wid.append(2)\n",
        "    elif \"[REAL]\" in line:\n",
        "        wid.append(real_wid)\n",
        "    elif \"[FAKE]\" in line:\n",
        "        wid.append(fake_wid)\n",
        "    else:\n",
        "      line = [token for token in word_tokenize(line.lower())]\n",
        "      for token in line:\n",
        "        word_info = word_dict.get(token)\n",
        "        if word_info is None:\n",
        "          wid.append(0)\n",
        "        elif word_info[1] < 30: # unk words with low frequency\n",
        "          wid.append(0)\n",
        "        else:\n",
        "          wid.append(word_info[0])\n",
        "\n",
        "  x = torch.tensor(np.asarray(wid))\n",
        "\n",
        "  num_batches = x.shape[0] // batch_size \n",
        "  x = x[:num_batches * batch_size]\n",
        "  x = x.view(batch_size, num_batches)  \n",
        "\n",
        "  return x\n",
        "\n",
        "def make_tensors(file_name,sequence_length):\n",
        "  '''\n",
        "  creates a list of tuples containing a list with the tokenized bio and a fake/real label\n",
        "\n",
        "  inputs: \n",
        "    file_name = a complete file path to a mixed dataset containing text and labels\n",
        "    sequence_length = the length of the desired input array\n",
        "  outputs:\n",
        "    x = a tensor containing wIDs of the desired sequence length for each bio\n",
        "    y = a tensor containing the corresponding label for each input\n",
        "  '''\n",
        "  \n",
        "  # stop = set(stopwords.words('english') + list(string.punctuation))\n",
        "\n",
        "\n",
        "  with open(file_name) as input:\n",
        "    all_text = input.readlines()\n",
        "\n",
        "# if anybody wants to do some work on the tokenization section, \n",
        "# you should work with the split_bios array, since it contains actual words\n",
        "\n",
        "# split_bios = [([bio1, tokens1],[REAL]),([bio2, tokens2],[FAKE])]\n",
        "  split_bios = []\n",
        "  line_text = []\n",
        "  seq_status = 0\n",
        "\n",
        "  # seq_status = 0 marks the start of the bio\n",
        "  # seq_status = 1 is the main text of the bio\n",
        "  # seq_status = 2 is the end of the bio\n",
        "  for line in all_text:\n",
        "    line = line.strip()\n",
        "    if \"< start_bio >\" in line:\n",
        "      seq_status = 0\n",
        "      continue\n",
        "    if \"< end_bio >\" in line:\n",
        "      seq_status = 2\n",
        "      line_text.append(line)\n",
        "      continue\n",
        "    if seq_status == 0:\n",
        "      # bio_person = line.strip(\" = \").lower().split()\n",
        "      # stop.update(bio_person) # could remove important words if name is meaningful\n",
        "      seq_status = 1\n",
        "    if seq_status == 1:\n",
        "      line = re.sub(\"[\\d-]\", \"\",line)\n",
        "      line = [token for token in word_tokenize(line.lower())]\n",
        "      # line = [token for token in word_tokenize(line.lower()) if token not in stop]\n",
        "      if len(line) > 0:\n",
        "        line_text.extend(line)\n",
        "    if seq_status == 2 and line !=\"\":\n",
        "      # stop -= set(bio_person)\n",
        "      # if line == '[FAKE]': #updated code so now fake / real is binary\n",
        "      #   line = 0\n",
        "      # elif line == '[REAL]':\n",
        "      #   line = 1\n",
        "      # else:\n",
        "      #   continue \n",
        "      split_bios.append((line_text,line))\n",
        "      line_text = []\n",
        "\n",
        "  encodings = read_encode(file_name,[],{},[],3)\n",
        "  word_dict = encodings[1]\n",
        "  vocab_length = max(encodings[2])\n",
        "\n",
        "  bio_array = []\n",
        "  seq_len = sequence_length\n",
        "  y = []\n",
        "\n",
        "  for bio in split_bios:\n",
        "    wid = []\n",
        "    for token in bio[0]:\n",
        "      word_info = word_dict.get(token)\n",
        "      if word_info is None:\n",
        "        wid.append(0)\n",
        "      else:\n",
        "        wid.append(word_info[0])\n",
        "    if len(wid) > seq_len:\n",
        "      wid = wid[:seq_len-2]\n",
        "      wid.append(word_dict.get('< end_bio >')[0]) #makes last token \"end bio\" no matter what\n",
        "      wid.append(word_dict.get(bio[1])[0])\n",
        "    # elif len(wid) < seq_len:\n",
        "    #   wid.append(word_dict.get(bio[1])[0])\n",
        "    #   pad_size = seq_len - len(wid)\n",
        "    #   wid.extend(np.ones(pad_size,dtype=int))\n",
        "    bio_array.append(np.asarray(wid))\n",
        "    y.append(word_dict.get(bio[1])[0])\n",
        "    # y.append(bio[1])\n",
        "\n",
        "  x = bio_array\n",
        "  y = torch.tensor(y)\n",
        "\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "S92xGxZAejT_"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text = read_alltext('/content/NLP-DL-Group2/hw#1/mix.train.tok',20)\n",
        "print(all_text[:,:20])"
      ],
      "metadata": {
        "id": "11k7TC1Bg8cm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b225f6-98a2-419e-a191-b5f793524fef"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    1,     6,     0,     0,     6,     0,     0,     9,    11,    13,\n",
            "            15,    17,    18,    19,    20,    21,    22,     0,    18,    23],\n",
            "        [    0,    18,  5102,   355,    38,   280,   281,    24,  3934,   461,\n",
            "            28,    24,     0,    38,   384,    13,    31,     0,   223,   374],\n",
            "        [   18,    37,    38,  1065,    46,  1382,    22,    37,    38,  1065,\n",
            "            46,    51,   262,   206,     0,    49,    19,     0,    49,  2839],\n",
            "        [  239,    31,    13,   130,    31,    17,    18,    19,   132,  1096,\n",
            "           791,    26,    43,   648,    22,    96,   504,    96, 19292,    18],\n",
            "        [   31,    19,     0,    49,    38,     0,    46,   593,  5965,     0,\n",
            "             9,    17,    31,    79,  1293,  7105,    24,    38,  1023,   180],\n",
            "        [    0,    26,     0,    34,    38,   922,    46,  4537,    34,    38,\n",
            "          6726,    46,   246,  5972,     9,     0,    22,  2306,    31,   538],\n",
            "        [   38,   272,    46,    38, 10087,   426,   374,  1403,     0,    46,\n",
            "          7964,    26, 10087,   374,     0,  1315,    31,   374,   354,     0],\n",
            "        [   46,    38,   503,   166,    46,    38,  4118,    48,    46, 10547,\n",
            "            24,    38,   683,  2306,    46,    38,     0,     0,   112,    46],\n",
            "        [   24,   132,    17,    22,  7033,   426,   214, 11226,    22,     0,\n",
            "          5523,     0,   214,    31,     0,   214,  3064,     0,   447,     0],\n",
            "        [  244,   164,   904,    22,    96,   884,    96,     0,   694,     0,\n",
            "            31,     0,    22,    24,    38,     0,   694,   886,  2726,   694],\n",
            "        [   22,   886,     0,  1270,     0,   175,     0,    31,    22,  3605,\n",
            "            46,  2961,   694,     0,    22,     2,   124,     1,     6,   395],\n",
            "        [   51,  1249,    81,     0,     0,    38,   816,    46,    38,  3041,\n",
            "            57, 11665,    22,    38,   328,    46,  5695,     0,    31,  1249],\n",
            "        [    0,     9,     0,    17,     9,    13,   566,    17,    18,    19,\n",
            "           132,  8373,   791,    26,   372,    22,    96,   504,    96,    51],\n",
            "        [   22,     0,    18,    85,   249,    46,    38,   302,     0,    46,\n",
            "           503,   787,  2663,  2568,     0,    22,    51,    18,    19,   155],\n",
            "        [ 2860,   116,    22,     0,   805,  5127,   152,    24,  2860,   116,\n",
            "            31,    46,    79,   147,    46,    38,  1819,     0,     0,   709],\n",
            "        [  106,  1338,    31,  1069,    51,   279,    19,  1193,   974,    37,\n",
            "          3703,  1206,    22,    24,    31,     0,   279,    19,   974,    57],\n",
            "        [  355,    19,   106,  6349,   340,   413,    42,    38,   138,    46,\n",
            "          6367,    24,  1637,    32,  3063,   553,  2961,     0,    22,    51],\n",
            "        [  254,    96,    51,    18,    23,    37,     0,  2065,     0,     0,\n",
            "             9,     0,    17,    22,    51,    18,    41,    24,    49,   159],\n",
            "        [  150,   653,    19,  1846,    34,  2168,    31,   651,    24,    22,\n",
            "            96,   504,    96,  1358,    18,    23,    24,    47,    24,   130],\n",
            "        [    0,   393,    24,   393,   653,    38,     0,     0,    22,     2,\n",
            "           637,     1,     6,     0,     0,     6,     0,     0,     9,   578]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_text.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjatzgGv7iGk",
        "outputId": "af438d15-8495-45b2-ccba-698254362a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([300, 9394])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data, seq_len, num_batches, idx):\n",
        "    src = data[:, idx:idx+seq_len]                   \n",
        "    target = data[:, idx+1:idx+seq_len+1]             \n",
        "    return src, target"
      ],
      "metadata": {
        "id": "DMmJcI2eVmzc"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self, vocab, words,d_model, d_hidden, dropout):\n",
        "        super().__init__() \n",
        "    \n",
        "        self.vocab = vocab\n",
        "        self.words = words\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.d_model = d_model\n",
        "        self.d_hidden = d_hidden\n",
        "        self.dropout = dropout\n",
        "        self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
        "#          {perform other initializations needed for the FFNN}\n",
        "\n",
        "    def forward(self, src):\n",
        "        embeds = self.dropout(self.embeds(src))\n",
        "#          {add code to implement the FFNN}\n",
        "        pass\n",
        "        # return x\n",
        "                \n",
        "    def init_weights(self):\n",
        "      pass\n",
        "#          {perform initializations}\n",
        "             \n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self,vocab,words,d_model,d_hidden,n_layers,dropout_rate, tie_weights):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.words = words\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.n_layers = n_layers\n",
        "        self.d_hidden = d_hidden\n",
        "        self.d_model = d_model\n",
        "        self.embeds = nn.Embedding(self.vocab_size,d_model)\n",
        "#          {perform other initializations needed for the LSTM}\n",
        "        self.lstm = nn.LSTM(2*d_model, d_hidden, n_layers, dropout=dropout_rate, bidirectional=True, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(2*d_hidden, self.vocab_size)\n",
        "\n",
        "        if tie_weights:\n",
        "          assert d_model == d_hidden, 'cannot tie, check dims'\n",
        "          self.embeds.weight = self.fc.weight\n",
        "        self.init_weights()\n",
        "        \n",
        "    def forward(self,src,h):\n",
        "        embeds = self.dropout(self.embeds(src)) \n",
        "        out, h = self.lstm(embeds, h)\n",
        "        out = self.dropout(out)\n",
        "        predict = self.fc(out)\n",
        "        return predict, h\n",
        "    \n",
        "    def init_weights(self):\n",
        "        emb_range = 0.1\n",
        "        init_range = 1/math.sqrt(self.d_hidden)\n",
        "        self.embeds.weight.data.uniform_(-emb_range, emb_range)\n",
        "        self.fc.weight.data.uniform_(-init_range, init_range)\n",
        "        self.fc.bias.data.zero_()\n",
        "        for i in range(self.n_layers):\n",
        "            self.lstm.all_weights[i][0] = torch.FloatTensor(self.d_model,\n",
        "                    self.d_hidden).uniform_(-init_range, init_range) \n",
        "            self.lstm.all_weights[i][1] = torch.FloatTensor(self.d_hidden, \n",
        "                    self.d_hidden).uniform_(-init_range, init_range) \n",
        "        \n",
        "    def init_hidden(self, batch_size, device):\n",
        "        hidden = torch.zeros(2*self.n_layers, batch_size, self.d_hidden).to(device)\n",
        "        cell = torch.zeros(2*self.n_layers, batch_size, self.d_hidden).to(device)\n",
        "        return hidden, cell\n",
        "\n",
        "    def detach_hidden(self, hidden):\n",
        "      hidden, cell = hidden\n",
        "      hidden = hidden.detach()\n",
        "      cell = cell.detach()\n",
        "      return hidden,cell\n",
        " \n",
        "def main():\n",
        "    \n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-d_model', type=int, default=100)\n",
        "    parser.add_argument('-d_hidden', type=int, default=100)\n",
        "    parser.add_argument('-n_layers', type=int, default=2)\n",
        "    parser.add_argument('-batch_size', type=int, default=20)\n",
        "    parser.add_argument('-seq_len', type=int, default=30)\n",
        "    parser.add_argument('-printevery', type=int, default=5000)\n",
        "    parser.add_argument('-window', type=int, default=3)\n",
        "    parser.add_argument('-epochs', type=int, default=20)\n",
        "    parser.add_argument('-lr', type=float, default=0.0001)\n",
        "    parser.add_argument('-dropout', type=int, default=0.35)\n",
        "    parser.add_argument('-clip', type=int, default=2.0)\n",
        "    parser.add_argument('-model', type=str,default='LSTM')\n",
        "    parser.add_argument('-savename', type=str,default='lstm')\n",
        "    parser.add_argument('-loadname', type=str)\n",
        "    parser.add_argument('-trainname', type=str,default='wiki.train.txt')\n",
        "    parser.add_argument('-validname', type=str,default='wiki.valid.txt')\n",
        "    parser.add_argument('-testname', type=str,default='wiki.test.txt')\n",
        "\n",
        "    params = {\n",
        "        'd_model': 512,\n",
        "        'd_hidden': 512,\n",
        "        'n_layers': 2,\n",
        "        'batch_size': 20,\n",
        "        'seq_len': 30,\n",
        "        'printevery': 500,\n",
        "        'window': 3,\n",
        "        'epochs': 20,\n",
        "        'lr': 0.0001,\n",
        "        'dropout': 0.35,\n",
        "        'clip': 2.0,\n",
        "        'model': 'LSTM',\n",
        "        'savename': 'lstm',\n",
        "        'loadname': None,\n",
        "        'trainname': '/content/NLP-DL-Group2/hw#1/mix.train.tok',\n",
        "        'validname': '/content/NLP-DL-Group2/hw#1/mix.valid.tok',\n",
        "        'testname': '/content/NLP-DL-Group2/hw#1/mix.test.tok'\n",
        "    }\n",
        "    parser.add_argument(\"-f\", required=False)\n",
        "    \n",
        "    # params = parser.parse_args()    \n",
        "    # torch.manual_seed(0)\n",
        "    \n",
        "    [vocab,words,train] = read_encode(params['trainname'],[],{},[],3)\n",
        "    print('vocab: %d train: %d' % (len(vocab),len(train)))\n",
        "    [vocab,words,test] = read_encode(params['testname'],vocab,words,[],-1)\n",
        "    print('vocab: %d test: %d' % (len(vocab),len(test)))\n",
        "    params['vocab_size'] = len(vocab)\n",
        "\n",
        "    train_loader = read_encode(params['trainname'],[],{},[],3)\n",
        "    \n",
        "    if params['model'] == 'FFNN':\n",
        "      pass\n",
        "#          {add code to instantiate the model, train for K epochs and save model to disk}\n",
        "        \n",
        "    if params['model'] == 'LSTM':\n",
        "      pass\n",
        "\n",
        "    if params['model'] == 'FFNN_CLASSIFY':\n",
        "      pass\n",
        "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n",
        "\n",
        "    if params['model'] == 'LSTM_CLASSIFY':\n",
        "      pass\n",
        "#          {add code to instantiate the model, recall model parameters and perform/learn classification}\n",
        "        \n",
        "    print(params)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwOAM-Ht6WMu",
        "outputId": "d2deffe2-6d20-4df0-b7ce-57a435b25852"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab: 35152 train: 3012820\n",
            "vocab: 35152 test: 395279\n",
            "{'d_model': 512, 'd_hidden': 512, 'n_layers': 2, 'batch_size': 20, 'seq_len': 30, 'printevery': 500, 'window': 3, 'epochs': 20, 'lr': 0.0001, 'dropout': 0.35, 'clip': 2.0, 'model': 'LSTM', 'savename': 'lstm', 'loadname': None, 'trainname': '/content/NLP-DL-Group2/hw#1/mix.train.tok', 'validname': '/content/NLP-DL-Group2/hw#1/mix.valid.tok', 'testname': '/content/NLP-DL-Group2/hw#1/mix.test.tok', 'vocab_size': 35152}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[vocab,words,train] = read_encode('/content/NLP-DL-Group2/hw#1/mix.train.tok',[],{},[],3)\n",
        "\n",
        "rmv_list = []\n",
        "\n",
        "for key,value in words.items():\n",
        "  if value[1] < 10:\n",
        "    rmv_list.append(value[0])\n",
        "\n",
        "print(len(rmv_list))\n",
        "\n",
        "updated_vocab = list(set(train) - set(rmv_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LgE9a7my2BJ",
        "outputId": "6002681f-8a72-4362-ee8e-02d7514de1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(updated_vocab))\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "id": "Ysi5yQfs0MNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  num_batches = data.shape[-1]\n",
        "  data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "  num_batches = data.shape[-1]\n",
        "\n",
        "  hidden = model.init_hidden(batch_size, device)\n",
        "    \n",
        "  for idx in range(0, num_batches - 1, seq_len):  # The last batch can't be a src\n",
        "      optimizer.zero_grad()\n",
        "      hidden = model.detach_hidden(hidden)\n",
        "\n",
        "      src, target = get_batch(data, seq_len, num_batches, idx)\n",
        "      src, target = src.to(device), target.to(device)\n",
        "      batch_size = src.shape[0]\n",
        "      prediction, hidden = model(src, hidden)               \n",
        "\n",
        "      prediction = prediction.reshape(batch_size * seq_len, -1)   \n",
        "      target = target.reshape(-1)\n",
        "      loss = criterion(prediction, target)\n",
        "      \n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item() * seq_len\n",
        "    \n",
        "  return math.exp(epoch_loss / num_batches)\n",
        "  \n",
        "# [vocab,words,train] = read_encode('/content/NLP-DL-Group2/hw#1/mix.train.tok',[],{},[],3)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# data = all_text\n",
        "# batch_size = 20\n",
        "# seq_len = 30\n",
        "# clip = 2.0\n",
        "\n",
        "# model = LSTM(vocab,words,512,512,2,.35,True) \n",
        "# optimizer = optim.Adam(model.parameters(), lr=.0008)\n",
        "# print(LSTM_train(model,data,optimizer,criterion,batch_size,seq_len,clip,device))"
      ],
      "metadata": {
        "id": "UhLLoJRoVxfx"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data, criterion, batch_size, seq_len, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    num_batches = data.shape[-1]\n",
        "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "    num_batches = data.shape[-1]\n",
        "\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, num_batches - 1, seq_len):\n",
        "            hidden = model.detach_hidden(hidden)\n",
        "            src, target = get_batch(data, seq_len, num_batches, idx)\n",
        "            src, target = src.to(device), target.to(device)\n",
        "            batch_size= src.shape[0]\n",
        "\n",
        "            prediction, hidden = model(src, hidden)\n",
        "            prediction = prediction.reshape(batch_size * seq_len, -1)\n",
        "            target = target.reshape(-1)\n",
        "\n",
        "            loss = criterion(prediction, target)\n",
        "            epoch_loss += loss.item() * seq_len\n",
        "    return math.exp(epoch_loss / num_batches)"
      ],
      "metadata": {
        "id": "pZCzdNJeQOXp"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "saved = True\n",
        "\n",
        "train_data = read_alltext('/content/NLP-DL-Group2/hw#1/mix.train.tok',20)\n",
        "valid_data = read_alltext('/content/NLP-DL-Group2/hw#1/mix.valid.tok',20)\n",
        "test_data = read_alltext('/content/NLP-DL-Group2/hw#1/mix.test.tok',20)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=.0008)\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n"
      ],
      "metadata": {
        "id": "aIBd96mQPexA"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    model.load_state_dict(torch.load('best-val-lstm_lm.pt',  map_location=device))\n",
        "    test_loss = evaluate(model, test_data, criterion, batch_size, seq_len, device)\n",
        "    print(f'Test Perplexity: {test_loss:.3f}')\n",
        "else:\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = LSTM_train(model, train_data, optimizer, criterion, \n",
        "                    20, seq_len, clip, device)\n",
        "        valid_loss = evaluate(model, valid_data, criterion, 20, \n",
        "                    seq_len, device)\n",
        "        \n",
        "        lr_scheduler.step(valid_loss)\n",
        "\n",
        "        print(f'\\tTrain Perplexity: {train_loss:.3f}')\n",
        "        print(f'\\tValid Perplexity: {valid_loss:.3f}')\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'best-val-lstm_lm.pt')"
      ],
      "metadata": {
        "id": "WT-rYeNiRfqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae98264-8c05-4dc5-e382-998434e064d7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Perplexity: 202.917\n",
            "\tValid Perplexity: 1157.129\n",
            "\tTrain Perplexity: 130.513\n",
            "\tValid Perplexity: 1031.146\n",
            "\tTrain Perplexity: 83.937\n",
            "\tValid Perplexity: 858.204\n",
            "\tTrain Perplexity: 59.727\n",
            "\tValid Perplexity: 813.640\n",
            "\tTrain Perplexity: 42.850\n",
            "\tValid Perplexity: 611.769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save code\n",
        "\n",
        "model.load_state_dict(torch.load('lstm_mixed_30_unk.pt',  map_location=device))\n",
        "test_loss = evaluate(model, test_data, criterion, batch_size, seq_len, device)\n",
        "print(f'Test Perplexity: {test_loss:.3f}')\n",
        "torch.save({\n",
        "            'epoch': 10,\n",
        "            'batch': 30,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': test_loss,\n",
        "            }, \"/content/drive/My Drive/lstm_mixed_30_unk.pt\")"
      ],
      "metadata": {
        "id": "-BA0eUPNkAei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yfzl-fVkLss",
        "outputId": "eb63cec0-3e8d-479d-ff26-0ad64ed122fe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word_tensors = make_tensors('/content/NLP-DL-Group2/hw#1/mix.train.tok',500)\n",
        "input = torch.tensor(word_tensors[0][0]).reshape(-1,1)\n",
        "\n",
        "def LSTM_Classify(input, model, vocab, word_dict, device, seed=None):\n",
        "  real_wid = word_dict.get('[REAL]')[0]\n",
        "  fake_wid = word_dict.get('[FAKE]')[0]\n",
        "  if seed is not None:\n",
        "      torch.manual_seed(seed)\n",
        "  model.eval()\n",
        "  batch_size = len(input)\n",
        "  hidden = model.init_hidden(batch_size, device)\n",
        "  with torch.no_grad():\n",
        "      src = input\n",
        "      prediction, hidden = model(src, hidden)\n",
        "      probs = torch.softmax(prediction[:, -1] , dim=-1)  \n",
        "      real_prediction = probs[-1][real_wid]\n",
        "      fake_prediction = probs[-1][fake_wid]\n",
        "      if real_prediction > fake_prediction:\n",
        "        prediction = real_wid\n",
        "      else:\n",
        "        prediction = fake_wid\n",
        "\n",
        "  return prediction\n",
        "\n",
        "LSTM_Classify(input,model,vocab,words,device)"
      ],
      "metadata": {
        "id": "7Y7A_zgdXpiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d543917-d330-4712-e758-87bcda74bb1c"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "637"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(words.get('[REAL]')[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxRS90VUJRB_",
        "outputId": "d1656cca-332e-4ad4-ad2c-2d11de0cc172"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(word_tensors[1]))\n",
        "\n",
        "correct = 0\n",
        "# for index in range(500):\n",
        "for index in range(len(word_tensors[1])):\n",
        "  item = torch.tensor(word_tensors[0][index]).reshape(-1,1)\n",
        "  prediction = LSTM_Classify(item,model,vocab,words,device)\n",
        "  actual = word_tensors[1][index]\n",
        "  if prediction == actual:\n",
        "    correct += 1\n",
        "  \n",
        "# print(correct/500)\n",
        "print(correct/len(word_tensors[1]))"
      ],
      "metadata": {
        "id": "4OO9-tp822wA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae8aeeb-8967-476b-9db3-7312e20c0684"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.26\n"
          ]
        }
      ]
    }
  ]
}